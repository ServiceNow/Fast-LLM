{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toolkit/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mamba_ssm import MambaLMHeadModel\n",
    "from mamba_ssm.models.config_mamba import MambaConfig\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "from fast_llm.models.ssm.external.aperiel_ssm.configuration_ssm_apriel import AprielSSMConfig\n",
    "from fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel import AprielSSMForCausalLM\n",
    "from transformers.cache_utils import StaticCache\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# make sure the code changes reflected without reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare trained SSM with lr scalors of 0 on everythign except of mixers, with innitial checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_base= \"/mnt/checkpoints/ssm/apriel_ssm_instruct_init_mambainlama\"\n",
    "checkpoint_trained = \"/mnt/checkpoints/fast_llm_exp/slam_ssm_distill/ssmins_chillmlp-rand_15bteacher-bs768-lr0.0001-sl4096_ti2000_lm2/export/apriel_ssm/500\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.29it/s]\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.49s/it]\n"
     ]
    }
   ],
   "source": [
    "model_base = AprielSSMForCausalLM.from_pretrained(checkpoint_base, torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "model_trained = AprielSSMForCausalLM.from_pretrained(checkpoint_trained, torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.8750, dtype=torch.bfloat16, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_base.model.layers[5].mlp.down_proj.weight.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.8750, dtype=torch.bfloat16, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trained.model.layers[5].mlp.down_proj.weight.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriel SSM for distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  9.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AprielForCausalLM(\n",
       "  (model): AprielModel(\n",
       "    (embed_tokens): Embedding(131072, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x AprielDecoderLayer(\n",
       "        (self_attn): AprielAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): AprielMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): AprielRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=131072, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = \"ServiceNow-AI/Apriel-5B-Instruct\"\n",
    "config = AutoConfig.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "apriel_model     = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "apriel_state_dict = apriel_model.state_dict()\n",
    "apriel_model.to(device).to(dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N params SSM: 4.83207168\n"
     ]
    }
   ],
   "source": [
    "print(\"N params SSM:\", sum(p.numel() for p in apriel_model.parameters() if p.requires_grad)/1e9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "apriel_ssm_config = AprielSSMConfig(vocab_size=config.vocab_size, \n",
    "                                    hidden_size=config.hidden_size,\n",
    "                                    intermediate_size=config.intermediate_size,\n",
    "                                    num_hidden_layers=config.num_hidden_layers,\n",
    "                                    hidden_act=config.hidden_act,\n",
    "                                    initializer_range=config.initializer_range,\n",
    "                                    use_cache=config.use_cache,\n",
    "                                    mlp_bias=config.mlp_bias,\n",
    "                                    tie_word_embeddings=config.tie_word_embeddings,\n",
    "                                    pad_token_id=config.pad_token_id,\n",
    "                                    bos_token_id=config.bos_token_id,\n",
    "                                    eos_token_id=config.eos_token_id,\n",
    "                                    rms_norm_eps=config.rms_norm_eps,\n",
    "                                    ssm_cfg={\n",
    "                                        \"d_state\": 64,\n",
    "                                        \"n_v_heads\": 24,\n",
    "                                        \"n_qk_heads\": 24,\n",
    "                                        \"expand\": 1,\n",
    "                                        \"chunk_size\": 128,\n",
    "                                        \"activation\": \"identity\",\n",
    "                                        \"bias\": False,\n",
    "                                        \"d_inner\": 4104,\n",
    "                                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "apriel_ssm = AprielSSMForCausalLM(apriel_ssm_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N params SSM: 5.660780512\n"
     ]
    }
   ],
   "source": [
    "print(\"N params SSM:\", sum(p.numel() for p in apriel_ssm.parameters() if p.requires_grad)/1e9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load State dict into SSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AprielSSMForCausalLM(\n",
       "  (model): AprielSSMModel(\n",
       "    (embed_tokens): Embedding(131072, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x AprielDecoderLayer(\n",
       "        (mixer): DiscreteMamba2(\n",
       "          (in_proj): Linear(in_features=4096, out_features=11304, bias=False)\n",
       "          (conv1d): Conv1d(7176, 7176, kernel_size=(4,), stride=(1,), padding=(3,), groups=7176)\n",
       "          (act): Identity()\n",
       "          (out_proj): Linear(in_features=4104, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): AprielMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=131072, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriel_ssm.to(device).to(dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['model.layers.0.mixer.z_bias', 'model.layers.0.mixer.D', 'model.layers.0.mixer.in_proj.weight', 'model.layers.0.mixer.conv1d.weight', 'model.layers.0.mixer.conv1d.bias', 'model.layers.0.mixer.out_proj.weight', 'model.layers.1.mixer.z_bias', 'model.layers.1.mixer.D', 'model.layers.1.mixer.in_proj.weight', 'model.layers.1.mixer.conv1d.weight', 'model.layers.1.mixer.conv1d.bias', 'model.layers.1.mixer.out_proj.weight', 'model.layers.2.mixer.z_bias', 'model.layers.2.mixer.D', 'model.layers.2.mixer.in_proj.weight', 'model.layers.2.mixer.conv1d.weight', 'model.layers.2.mixer.conv1d.bias', 'model.layers.2.mixer.out_proj.weight', 'model.layers.3.mixer.z_bias', 'model.layers.3.mixer.D', 'model.layers.3.mixer.in_proj.weight', 'model.layers.3.mixer.conv1d.weight', 'model.layers.3.mixer.conv1d.bias', 'model.layers.3.mixer.out_proj.weight', 'model.layers.4.mixer.z_bias', 'model.layers.4.mixer.D', 'model.layers.4.mixer.in_proj.weight', 'model.layers.4.mixer.conv1d.weight', 'model.layers.4.mixer.conv1d.bias', 'model.layers.4.mixer.out_proj.weight', 'model.layers.5.mixer.z_bias', 'model.layers.5.mixer.D', 'model.layers.5.mixer.in_proj.weight', 'model.layers.5.mixer.conv1d.weight', 'model.layers.5.mixer.conv1d.bias', 'model.layers.5.mixer.out_proj.weight', 'model.layers.6.mixer.z_bias', 'model.layers.6.mixer.D', 'model.layers.6.mixer.in_proj.weight', 'model.layers.6.mixer.conv1d.weight', 'model.layers.6.mixer.conv1d.bias', 'model.layers.6.mixer.out_proj.weight', 'model.layers.7.mixer.z_bias', 'model.layers.7.mixer.D', 'model.layers.7.mixer.in_proj.weight', 'model.layers.7.mixer.conv1d.weight', 'model.layers.7.mixer.conv1d.bias', 'model.layers.7.mixer.out_proj.weight', 'model.layers.8.mixer.z_bias', 'model.layers.8.mixer.D', 'model.layers.8.mixer.in_proj.weight', 'model.layers.8.mixer.conv1d.weight', 'model.layers.8.mixer.conv1d.bias', 'model.layers.8.mixer.out_proj.weight', 'model.layers.9.mixer.z_bias', 'model.layers.9.mixer.D', 'model.layers.9.mixer.in_proj.weight', 'model.layers.9.mixer.conv1d.weight', 'model.layers.9.mixer.conv1d.bias', 'model.layers.9.mixer.out_proj.weight', 'model.layers.10.mixer.z_bias', 'model.layers.10.mixer.D', 'model.layers.10.mixer.in_proj.weight', 'model.layers.10.mixer.conv1d.weight', 'model.layers.10.mixer.conv1d.bias', 'model.layers.10.mixer.out_proj.weight', 'model.layers.11.mixer.z_bias', 'model.layers.11.mixer.D', 'model.layers.11.mixer.in_proj.weight', 'model.layers.11.mixer.conv1d.weight', 'model.layers.11.mixer.conv1d.bias', 'model.layers.11.mixer.out_proj.weight', 'model.layers.12.mixer.z_bias', 'model.layers.12.mixer.D', 'model.layers.12.mixer.in_proj.weight', 'model.layers.12.mixer.conv1d.weight', 'model.layers.12.mixer.conv1d.bias', 'model.layers.12.mixer.out_proj.weight', 'model.layers.13.mixer.z_bias', 'model.layers.13.mixer.D', 'model.layers.13.mixer.in_proj.weight', 'model.layers.13.mixer.conv1d.weight', 'model.layers.13.mixer.conv1d.bias', 'model.layers.13.mixer.out_proj.weight', 'model.layers.14.mixer.z_bias', 'model.layers.14.mixer.D', 'model.layers.14.mixer.in_proj.weight', 'model.layers.14.mixer.conv1d.weight', 'model.layers.14.mixer.conv1d.bias', 'model.layers.14.mixer.out_proj.weight', 'model.layers.15.mixer.z_bias', 'model.layers.15.mixer.D', 'model.layers.15.mixer.in_proj.weight', 'model.layers.15.mixer.conv1d.weight', 'model.layers.15.mixer.conv1d.bias', 'model.layers.15.mixer.out_proj.weight', 'model.layers.16.mixer.z_bias', 'model.layers.16.mixer.D', 'model.layers.16.mixer.in_proj.weight', 'model.layers.16.mixer.conv1d.weight', 'model.layers.16.mixer.conv1d.bias', 'model.layers.16.mixer.out_proj.weight', 'model.layers.17.mixer.z_bias', 'model.layers.17.mixer.D', 'model.layers.17.mixer.in_proj.weight', 'model.layers.17.mixer.conv1d.weight', 'model.layers.17.mixer.conv1d.bias', 'model.layers.17.mixer.out_proj.weight', 'model.layers.18.mixer.z_bias', 'model.layers.18.mixer.D', 'model.layers.18.mixer.in_proj.weight', 'model.layers.18.mixer.conv1d.weight', 'model.layers.18.mixer.conv1d.bias', 'model.layers.18.mixer.out_proj.weight', 'model.layers.19.mixer.z_bias', 'model.layers.19.mixer.D', 'model.layers.19.mixer.in_proj.weight', 'model.layers.19.mixer.conv1d.weight', 'model.layers.19.mixer.conv1d.bias', 'model.layers.19.mixer.out_proj.weight', 'model.layers.20.mixer.z_bias', 'model.layers.20.mixer.D', 'model.layers.20.mixer.in_proj.weight', 'model.layers.20.mixer.conv1d.weight', 'model.layers.20.mixer.conv1d.bias', 'model.layers.20.mixer.out_proj.weight', 'model.layers.21.mixer.z_bias', 'model.layers.21.mixer.D', 'model.layers.21.mixer.in_proj.weight', 'model.layers.21.mixer.conv1d.weight', 'model.layers.21.mixer.conv1d.bias', 'model.layers.21.mixer.out_proj.weight', 'model.layers.22.mixer.z_bias', 'model.layers.22.mixer.D', 'model.layers.22.mixer.in_proj.weight', 'model.layers.22.mixer.conv1d.weight', 'model.layers.22.mixer.conv1d.bias', 'model.layers.22.mixer.out_proj.weight', 'model.layers.23.mixer.z_bias', 'model.layers.23.mixer.D', 'model.layers.23.mixer.in_proj.weight', 'model.layers.23.mixer.conv1d.weight', 'model.layers.23.mixer.conv1d.bias', 'model.layers.23.mixer.out_proj.weight', 'model.layers.24.mixer.z_bias', 'model.layers.24.mixer.D', 'model.layers.24.mixer.in_proj.weight', 'model.layers.24.mixer.conv1d.weight', 'model.layers.24.mixer.conv1d.bias', 'model.layers.24.mixer.out_proj.weight', 'model.layers.25.mixer.z_bias', 'model.layers.25.mixer.D', 'model.layers.25.mixer.in_proj.weight', 'model.layers.25.mixer.conv1d.weight', 'model.layers.25.mixer.conv1d.bias', 'model.layers.25.mixer.out_proj.weight', 'model.layers.26.mixer.z_bias', 'model.layers.26.mixer.D', 'model.layers.26.mixer.in_proj.weight', 'model.layers.26.mixer.conv1d.weight', 'model.layers.26.mixer.conv1d.bias', 'model.layers.26.mixer.out_proj.weight', 'model.layers.27.mixer.z_bias', 'model.layers.27.mixer.D', 'model.layers.27.mixer.in_proj.weight', 'model.layers.27.mixer.conv1d.weight', 'model.layers.27.mixer.conv1d.bias', 'model.layers.27.mixer.out_proj.weight'], unexpected_keys=['model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.27.self_attn.o_proj.weight'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriel_ssm.load_state_dict(apriel_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AprielSSMForCausalLM(\n",
       "  (model): AprielSSMModel(\n",
       "    (embed_tokens): Embedding(131072, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x AprielDecoderLayer(\n",
       "        (mixer): DiscreteMamba2(\n",
       "          (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "          (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "          (act): Identity()\n",
       "          (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): AprielMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=131072, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "apriel_ssm.to(device).to(dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toolkit/.local/lib/python3.12/site-packages/transformers/modeling_utils.py:2714: UserWarning: `save_config` is deprecated and will be removed in v5 of Transformers. Use `is_main_process` instead.\n",
      "  warnings.warn(\n",
      "WARNING:fast_llm.models.ssm.external.aperiel_ssm.configuration_ssm_apriel:Head dim is equal to d_inner // n_qk_heads.\n",
      "WARNING:fast_llm.models.ssm.external.aperiel_ssm.configuration_ssm_apriel:Head dim is equal to d_inner // n_qk_heads.\n",
      "WARNING:fast_llm.models.ssm.external.aperiel_ssm.configuration_ssm_apriel:Head dim is equal to d_inner // n_qk_heads.\n"
     ]
    }
   ],
   "source": [
    "apriel_ssm.save_pretrained(\"/mnt/checkpoints/ssm/apriel_ssm_instruct_base_din4104\", save_config=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Shambhavi's checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.07it/s]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"ServiceNow-AI/Apriel-5B-Instruct\"\n",
    "apriel_model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=torch.bfloat16, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriel_model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:fast_llm.models.ssm.external.aperiel_ssm.configuration_ssm_apriel:Head dim is equal to d_inner // n_qk_heads.\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.61s/it]\n"
     ]
    }
   ],
   "source": [
    "apriel_ssm = AprielSSMForCausalLM.from_pretrained(\n",
    "    \"/mnt/checkpoints_fml/pretrained_models/ssm/runs/mohawk_distributed_stage2_apriel_8GPU/checkpoints/final\",\n",
    "    # \"/mnt/checkpoints_fml/pretrained_models/ssm/apriel_ssm_instruct_base\",\n",
    "      trust_remote_code=True,\n",
    "      device=\"cuda\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriel_ssm.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriel_ssm.device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "input_ids = torch.randint(0, 32000, (1, 128), dtype=torch.long, device=device)\n",
    "batch_size = 1\n",
    "max_length = 128\n",
    "state = SimpleNamespace()\n",
    "state.key_value_memory_dict = apriel_ssm.allocate_inference_cache(batch_size, max_length, dtype=torch.bfloat16)\n",
    "state.batch_size = batch_size\n",
    "state.seqlen_offset = 0\n",
    "static_inputs = {\"inference_params\": state,\n",
    "        \"input_ids\": input_ids,\n",
    "        \"use_cache\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AprielSSMForCausalLM(\n",
       "  (model): AprielSSMModel(\n",
       "    (embed_tokens): Embedding(131072, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x AprielDecoderLayer(\n",
       "        (mixer): DiscreteMamba2(\n",
       "          (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "          (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "          (act): Identity()\n",
       "          (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): AprielMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=131072, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriel_ssm.to(device)#.to(dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomMambaCausalLMOutput(loss=None, logits=tensor([[[-5.4375,  0.3457, -2.2500,  ..., -5.2500, -4.6250, -4.2500],\n",
       "         [ 1.1016, -1.2734,  0.3320,  ..., -1.8828,  0.5508, -2.0938],\n",
       "         [-2.4531,  1.0078,  5.6562,  ..., -3.8906, -4.0625, -3.0625],\n",
       "         ...,\n",
       "         [-2.6250,  1.5234, -1.0312,  ..., -4.4062, -4.3438, -1.3594],\n",
       "         [-7.0000, -2.0781,  4.6250,  ..., -4.4688, -2.9688, -1.5156],\n",
       "         [-5.7188,  1.2891, -0.2109,  ..., -5.7500, -4.8438, -4.2812]]],\n",
       "       device='cuda:0', dtype=torch.float32, grad_fn=<ToCopyBackward0>), all_hidden_states=(), last_hidden_state=tensor([[[ 0.7344,  0.8555, -3.6562,  ..., -1.9688, -0.3516,  2.0625],\n",
       "         [-0.0986,  0.5859, -0.0806,  ..., -0.3965, -0.0229, -0.0219],\n",
       "         [ 0.3477,  0.5977, -1.0000,  ..., -0.6367, -1.1172, -0.6797],\n",
       "         ...,\n",
       "         [ 1.2969,  0.6562, -1.9844,  ..., -0.1299, -1.5859,  2.5000],\n",
       "         [ 1.8750, -0.6016, -3.3281,  ..., -0.8242,  0.6133,  3.1250],\n",
       "         [ 0.2520, -0.7656,  0.6133,  ..., -2.1875,  0.3770,  4.9062]]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriel_ssm.forward(**static_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Apriel SSM into HF class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mamba_ssm import MambaLMHeadModel\n",
    "from mamba_ssm.models.config_mamba import MambaConfig\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "from fast_llm.models.ssm.external.aperiel_ssm.configuration_ssm_apriel import AprielSSMConfig\n",
    "from fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel import AprielSSMForCausalLM\n",
    "from transformers.cache_utils import StaticCache\n",
    "from types import SimpleNamespace\n",
    "import os\n",
    "import shutil\n",
    "# make sure the code changes reflected without reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/mnt/checkpoints/fast_llm_exp/slam_ssm_distill/apriel_ssminstr-distil-randinit-bs768-lr0.0003-sl4096_ti5000_luke_mix1/export/apriel_ssm/5000\"\n",
    "modeling_path = \"/home/toolkit/dev/Fast-LLM/fast_llm/models/ssm/external\"\n",
    "# # copy the config.json to the model path\n",
    "shutil.copy(os.path.join(modeling_path, \"modeling_ssm_apriel.py\"), os.path.join(model_path, \"modeling_ssm_apriel.py\"))\n",
    "shutil.copy(os.path.join(modeling_path, \"configuration_ssm_apriel.py\"), os.path.join(model_path, \"configuration_ssm_apriel.py\"))\n",
    "\n",
    "tokenizer_path = \"/mnt/checkpoints/upstream/Mistral-Nemo-Base-2407/\"\n",
    "# # cp tokenizer*\n",
    "# shutil.copy(os.path.join(tokenizer_path, \"tokenizer.json\"), os.path.join(model_path, \"tokenizer.json\"))\n",
    "# shutil.copy(os.path.join(tokenizer_path, \"tokenizer_config.json\"), os.path.join(model_path, \"tokenizer_config.json\"))\n",
    "# shutil.copy(os.path.join(tokenizer_path, \"special_tokens_map.json\"), os.path.join(model_path, \"special_tokens_map.json\"))\n",
    "# shutil.copy(os.path.join(tokenizer_path, \"vocab.json\"), os.path.join(model_path, \"vocab.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "apriel_ssm = AprielSSMForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, trust_remote_code=True, device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AprielSSMForCausalLM(\n",
       "  (model): AprielSSMModel(\n",
       "    (embed_tokens): Embedding(131072, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x AprielDecoderLayer(\n",
       "        (mixer): DiscreteMamba2(\n",
       "          (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "          (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "          (act): Identity()\n",
       "          (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): AprielMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=131072, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriel_ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = apriel_ssm.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mamba in Llama: SSM hybrid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from fast_llm.models.ssm.external.aperiel_ssm.configuration_ssm_apriel import AprielSSMConfig\n",
    "import torch\n",
    "from mamba_ssm import MambaLMHeadModel\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "from fast_llm.models.ssm.external.aperiel_ssm.configuration_ssm_apriel import AprielSSMConfig\n",
    "from fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel import AprielSSMForCausalLM\n",
    "from transformers.cache_utils import StaticCache\n",
    "from types import SimpleNamespace\n",
    "from fast_llm.models.ssm.external.apriel_hybrid.modeling_ssm_hybrid_apriel import AprielSSMHybridConfig\n",
    "from fast_llm.models.ssm.external.apriel_hybrid.modeling_ssm_hybrid_apriel import AprielSSMHybridModel, AprielSSMDecoderLayer, AprielSSMHybridForCausalLM, AprielIdentityLayer\n",
    "# from fast_llm.models.ssm.external.__hybrid_wrapper import MambaTransformerHybridModelWrapper\n",
    "# make sure the code changes reflected without reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 0.612615\n",
    "layer_scores = {\n",
    "    \"22\": 0.607389,\n",
    "    \"24\": 0.603498,\n",
    "    \"19\": 0.597907,\n",
    "    \"27\": 0.597173,\n",
    "    \"20\": 0.590442,\n",
    "    \"5\": 0.578949,\n",
    "    \"4\": 0.576852,\n",
    "    \"9\": 0.576484,\n",
    "    \"23\": 0.574833,\n",
    "    \"7\": 0.571860,\n",
    "    \"8\": 0.571790,\n",
    "    \"6\": 0.571614,\n",
    "    \"2\": 0.571330,\n",
    "    \"26\": 0.570205,\n",
    "    \"11\": 0.567128,\n",
    "    \"14\": 0.566175,\n",
    "    \"15\": 0.566076,\n",
    "    \"3\": 0.562861,\n",
    "    \"1\": 0.560154,\n",
    "    \"13\": 0.559304,\n",
    "    \"16\": 0.559017,\n",
    "    \"10\": 0.558789,\n",
    "    \"12\": 0.555186,\n",
    "    \"17\": 0.554236,\n",
    "    \"25\": 0.549215,\n",
    "    \"18\": 0.537257,\n",
    "    \"0\": 0.233085,\n",
    "}\n",
    "layer_scores = {k: base - v for k, v in layer_scores.items()}\n",
    "layer_importanfce = sorted(layer_scores.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('22', 0.005226000000000064),\n",
       " ('24', 0.009117000000000042),\n",
       " ('19', 0.014708000000000054),\n",
       " ('27', 0.015442000000000067),\n",
       " ('20', 0.022173),\n",
       " ('5', 0.033665999999999974),\n",
       " ('4', 0.03576299999999999),\n",
       " ('9', 0.036131000000000024),\n",
       " ('23', 0.03778199999999998),\n",
       " ('7', 0.040754999999999986),\n",
       " ('8', 0.040825),\n",
       " ('6', 0.041001000000000065),\n",
       " ('2', 0.041285000000000016),\n",
       " ('26', 0.04241000000000006),\n",
       " ('11', 0.045487000000000055),\n",
       " ('14', 0.04644000000000004),\n",
       " ('15', 0.046539),\n",
       " ('3', 0.049754000000000076),\n",
       " ('1', 0.05246099999999998),\n",
       " ('13', 0.053311),\n",
       " ('16', 0.053598000000000035),\n",
       " ('10', 0.05382600000000004),\n",
       " ('12', 0.05742900000000006),\n",
       " ('17', 0.05837900000000007),\n",
       " ('25', 0.06340000000000001),\n",
       " ('18', 0.07535800000000004),\n",
       " ('0', 0.37953000000000003)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_importanfce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = \"ServiceNow-AI/Apriel-5B-Instruct\"\n",
    "# checkpoint = \"/mnt/checkpoints/upstream/Apriel-5B-Instruct-llamafied\"\n",
    "config = AutoConfig.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "device = \"cuda\"\n",
    "n_hybrid = 14\n",
    "\n",
    "\n",
    "# d_xb = config.num_key_value_heads * config.head_dim\n",
    "d_inner = config.num_attention_heads * config.head_dim\n",
    "d_state = config.head_dim\n",
    "\n",
    "# config.num_hidden_layers = 4\n",
    "hybrid_block_layout = [\"t\", \"t\"] * 14\n",
    "for i in range(n_hybrid):\n",
    "    hybrid_block_layout[int(layer_importanfce[i][0])] = \"m2d\"\n",
    "\n",
    "hybrdif_apriel_config = AprielSSMHybridConfig(**config.to_dict(),\n",
    "                                              hybrid_block_layout=hybrid_block_layout,\n",
    "                                              ssm_cfg={\n",
    "                                                  \"d_state\": 64,\n",
    "                                                  \"n_v_heads\": 24,\n",
    "                                                  \"n_qk_heads\": 24,\n",
    "                                                  \"expand\": 1,\n",
    "                                                  \"chunk_size\": 128,\n",
    "                                                  \"activation\": \"identity\",\n",
    "                                                  \"bias\": False,\n",
    "                                                  \"d_inner\": 24 * 128,  # num_heads * head_dim\n",
    "                                              })\n",
    "# hybrdif_apriel_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_apriel_model = AprielSSMHybridForCausalLM(hybrdif_apriel_config)\n",
    "# hybrid_apriel_model.to(device).to(dtype=torch.bfloat16)\n",
    "hybrid_apriel_model.to(dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save random small model for debugging\n",
    "# hybrid_apriel_model.save_pretrained(\"/mnt/checkpoints/ssm/apriel_ssm_instruct_hybrid_ssm2nd_init_mambainlama_debug\", save_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.47it/s]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"ServiceNow-AI/Apriel-5B-Instruct\"\n",
    "# checkpoint = \"/mnt/checkpoints/upstream/Apriel-5B-Instruct-llamafied\"\n",
    "config = AutoConfig.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "apriel_model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "# apriel_state_dict = apriel_model.state_dict()\n",
    "# apriel_model.to(device).to(dtype=torch.bfloat16)\n",
    "apriel_state_dict = apriel_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['model.layers.2.mixer.z_bias', 'model.layers.2.mixer.D', 'model.layers.2.mixer.in_proj.weight', 'model.layers.2.mixer.conv1d.weight', 'model.layers.2.mixer.conv1d.bias', 'model.layers.2.mixer.out_proj.weight', 'model.layers.4.mixer.z_bias', 'model.layers.4.mixer.D', 'model.layers.4.mixer.in_proj.weight', 'model.layers.4.mixer.conv1d.weight', 'model.layers.4.mixer.conv1d.bias', 'model.layers.4.mixer.out_proj.weight', 'model.layers.5.mixer.z_bias', 'model.layers.5.mixer.D', 'model.layers.5.mixer.in_proj.weight', 'model.layers.5.mixer.conv1d.weight', 'model.layers.5.mixer.conv1d.bias', 'model.layers.5.mixer.out_proj.weight', 'model.layers.6.mixer.z_bias', 'model.layers.6.mixer.D', 'model.layers.6.mixer.in_proj.weight', 'model.layers.6.mixer.conv1d.weight', 'model.layers.6.mixer.conv1d.bias', 'model.layers.6.mixer.out_proj.weight', 'model.layers.7.mixer.z_bias', 'model.layers.7.mixer.D', 'model.layers.7.mixer.in_proj.weight', 'model.layers.7.mixer.conv1d.weight', 'model.layers.7.mixer.conv1d.bias', 'model.layers.7.mixer.out_proj.weight', 'model.layers.8.mixer.z_bias', 'model.layers.8.mixer.D', 'model.layers.8.mixer.in_proj.weight', 'model.layers.8.mixer.conv1d.weight', 'model.layers.8.mixer.conv1d.bias', 'model.layers.8.mixer.out_proj.weight', 'model.layers.9.mixer.z_bias', 'model.layers.9.mixer.D', 'model.layers.9.mixer.in_proj.weight', 'model.layers.9.mixer.conv1d.weight', 'model.layers.9.mixer.conv1d.bias', 'model.layers.9.mixer.out_proj.weight', 'model.layers.19.mixer.z_bias', 'model.layers.19.mixer.D', 'model.layers.19.mixer.in_proj.weight', 'model.layers.19.mixer.conv1d.weight', 'model.layers.19.mixer.conv1d.bias', 'model.layers.19.mixer.out_proj.weight', 'model.layers.20.mixer.z_bias', 'model.layers.20.mixer.D', 'model.layers.20.mixer.in_proj.weight', 'model.layers.20.mixer.conv1d.weight', 'model.layers.20.mixer.conv1d.bias', 'model.layers.20.mixer.out_proj.weight', 'model.layers.22.mixer.z_bias', 'model.layers.22.mixer.D', 'model.layers.22.mixer.in_proj.weight', 'model.layers.22.mixer.conv1d.weight', 'model.layers.22.mixer.conv1d.bias', 'model.layers.22.mixer.out_proj.weight', 'model.layers.23.mixer.z_bias', 'model.layers.23.mixer.D', 'model.layers.23.mixer.in_proj.weight', 'model.layers.23.mixer.conv1d.weight', 'model.layers.23.mixer.conv1d.bias', 'model.layers.23.mixer.out_proj.weight', 'model.layers.24.mixer.z_bias', 'model.layers.24.mixer.D', 'model.layers.24.mixer.in_proj.weight', 'model.layers.24.mixer.conv1d.weight', 'model.layers.24.mixer.conv1d.bias', 'model.layers.24.mixer.out_proj.weight', 'model.layers.26.mixer.z_bias', 'model.layers.26.mixer.D', 'model.layers.26.mixer.in_proj.weight', 'model.layers.26.mixer.conv1d.weight', 'model.layers.26.mixer.conv1d.bias', 'model.layers.26.mixer.out_proj.weight', 'model.layers.27.mixer.z_bias', 'model.layers.27.mixer.D', 'model.layers.27.mixer.in_proj.weight', 'model.layers.27.mixer.conv1d.weight', 'model.layers.27.mixer.conv1d.bias', 'model.layers.27.mixer.out_proj.weight'], unexpected_keys=['model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.27.self_attn.o_proj.weight'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_apriel_model.load_state_dict(apriel_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Innitiating SSM layer\n",
      "Innitiating SSM layer\n",
      "Innitiating SSM layer\n",
      "Innitiating SSM layer\n",
      "Innitiating SSM layer\n",
      "Innitiating SSM layer\n",
      "Innitiating SSM layer\n",
      "Innitiating SSM layer\n",
      "Innitiating SSM layer\n",
      "Innitiating SSM layer\n",
      "Innitiating SSM layer\n",
      "Innitiating SSM layer\n",
      "Innitiating SSM layer\n",
      "Innitiating SSM layer\n"
     ]
    }
   ],
   "source": [
    "# Innitialization using k, q, v from Apriel transformer\n",
    "def expand_k_q(k):\n",
    "    Hq = config.num_attention_heads\n",
    "    Hk = config.num_key_value_heads\n",
    "    d_head = config.head_dim\n",
    "    d = k.shape[-1]\n",
    "    \n",
    "    # Expand k\n",
    "    repeat_factor = Hq // Hk\n",
    "    k_expanded = k.view(Hk, d_head, d)\n",
    "    k_expanded = k_expanded.repeat_interleave(repeat_factor, dim=0)\n",
    "    k_expanded = k_expanded.view(d_head * Hq, d)\n",
    "    return k_expanded\n",
    "\n",
    "def mil_innit(hybrid_apriel_model, apriel_model, SSMBLOCKCLASS = AprielSSMDecoderLayer):\n",
    "    for i, (block_h, block_t) in enumerate(zip(hybrid_apriel_model.model.layers, apriel_model.model.layers)):\n",
    "        # print(isinstance(block_h, AprielSSMDecoderLayer))\n",
    "        # print(i, block_h.__class__)\n",
    "        # print(block_h.__class__.__name__, isinstance(block_h, SSMBLOCKCLASS))\n",
    "        if isinstance(block_h, SSMBLOCKCLASS):\n",
    "            print(\"Innitiating SSM layer\")\n",
    "            # print(block_h.mixer.n_v_heads)\n",
    "            # print(block_t.self_attn.v_proj.weight.shape)\n",
    "            # print(block_h.mixer.in_proj.weight.shape)\n",
    "\n",
    "            # print(block_h.mixer.in_proj.weight.shape)\n",
    "            # print(block_t.self_attn.v_proj.weight.shape)\n",
    "            block_h.mlp.load_state_dict(block_t.mlp.state_dict())\n",
    "            block_h.input_layernorm.load_state_dict(block_t.input_layernorm.state_dict())\n",
    "            block_h.post_attention_layernorm.load_state_dict(block_t.post_attention_layernorm.state_dict())\n",
    "            block_h.mixer.out_proj.load_state_dict(block_t.self_attn.o_proj.state_dict())\n",
    "            # [x B C z A_log]\n",
    "            # print(block_h.mixer.d_inner)\n",
    "            # init x, but interleave to address GQA\n",
    "            v_expended = expand_k_q(block_t.self_attn.v_proj.weight.data)\n",
    "            block_h.mixer.in_proj.weight.data[:block_h.mixer.d_inner, : ].copy_(v_expended)\n",
    "            # init k, but interleave to address GQA\n",
    "            k_expended = expand_k_q(block_t.self_attn.k_proj.weight.data)\n",
    "            block_h.mixer.in_proj.weight.data[block_h.mixer.d_inner: 2*block_h.mixer.d_inner, : ].copy_(k_expended)\n",
    "            # init C ewith Q\n",
    "            block_h.mixer.in_proj.weight.data[2*block_h.mixer.d_inner: 3*block_h.mixer.d_inner, : ].copy_(block_t.self_attn.q_proj.weight.data)\n",
    "        else:\n",
    "            if not isinstance(block_h, AprielIdentityLayer):\n",
    "                assert sum([p.sum() for p in block_h.state_dict().values()]) == sum([p.sum() for p in block_t.state_dict().values()])\n",
    "            else:\n",
    "                print(\"Identity layer\")\n",
    "\n",
    "mil_innit(hybrid_apriel_model, apriel_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AprielSSMHybridConfig {\n",
       "  \"_name_or_path\": \"ServiceNow-AI/Apriel-5B-Instruct\",\n",
       "  \"architectures\": [\n",
       "    \"AprielSSMHybridForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"auto_map\": {\n",
       "    \"AutoConfig\": \"ServiceNow-AI/Apriel-5B-Instruct--configuration_apriel.AprielConfig\",\n",
       "    \"AutoModelForCausalLM\": \"ServiceNow-AI/Apriel-5B-Instruct--modeling_apriel.AprielForCausalLM\"\n",
       "  },\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"head_dim\": 128,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"hybrid_block_layout\": [\n",
       "    \"t\",\n",
       "    \"t\",\n",
       "    \"m2d\",\n",
       "    \"t\",\n",
       "    \"m2d\",\n",
       "    \"m2d\",\n",
       "    \"m2d\",\n",
       "    \"m2d\",\n",
       "    \"m2d\",\n",
       "    \"m2d\",\n",
       "    \"t\",\n",
       "    \"t\",\n",
       "    \"t\",\n",
       "    \"t\",\n",
       "    \"t\",\n",
       "    \"t\",\n",
       "    \"t\",\n",
       "    \"t\",\n",
       "    \"t\",\n",
       "    \"m2d\",\n",
       "    \"m2d\",\n",
       "    \"t\",\n",
       "    \"m2d\",\n",
       "    \"m2d\",\n",
       "    \"m2d\",\n",
       "    \"t\",\n",
       "    \"m2d\",\n",
       "    \"m2d\"\n",
       "  ],\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 8192,\n",
       "  \"max_position_embeddings\": 16384,\n",
       "  \"mlp_bias\": false,\n",
       "  \"model_type\": \"apriel_ssm_hybrid\",\n",
       "  \"num_attention_heads\": 24,\n",
       "  \"num_hidden_layers\": 28,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": {\n",
       "    \"attention_factor\": null,\n",
       "    \"beta_fast\": 32.0,\n",
       "    \"beta_slow\": 1.0,\n",
       "    \"factor\": 32.0,\n",
       "    \"original_max_position_embeddings\": 4096,\n",
       "    \"rope_type\": \"yarn\"\n",
       "  },\n",
       "  \"rope_theta\": 1000000.0,\n",
       "  \"ssm_cfg\": {\n",
       "    \"activation\": \"identity\",\n",
       "    \"bias\": false,\n",
       "    \"chunk_size\": 128,\n",
       "    \"d_conv\": 4,\n",
       "    \"d_inner\": 3072,\n",
       "    \"d_state\": 64,\n",
       "    \"expand\": 1,\n",
       "    \"n_qk_heads\": 24,\n",
       "    \"n_v_heads\": 24\n",
       "  },\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.48.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 131072\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_apriel_model.config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Hybrid checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toolkit/.local/lib/python3.12/site-packages/transformers/modeling_utils.py:2714: UserWarning: `save_config` is deprecated and will be removed in v5 of Transformers. Use `is_main_process` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# hybrid_apriel_model.save_pretrained(\"/mnt/checkpoints/ssm/apriel_ssm_instruct_hybrid_ssm2nd_init_mambainlama\", save_config=True)\n",
    "# hybrid_apriel_model.save_pretrained(\"/mnt/checkpoints/ssm/apriel_ssm_instruct_fulltransformer_init_mambainlama\", save_config=True)\n",
    "# hybrid_apriel_model.save_pretrained(\"/mnt/checkpoints/ssm/apriel_ssm_instruct_hybrid_test_init_mambainlama\", save_config=True)\n",
    "hybrid_apriel_model.save_pretrained(\"/mnt/checkpoints/ssm/apriel_ssm_instruct_hybrid_14ssm_leastimportant_init_mambainlama\", save_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "reloaded_model = AprielSSMHybridModel.from_pretrained(\"/mnt/checkpoints/ssm/apriel_ssm_instruct_hybrid_ssm2nd_init_mambainlama\", torch_dtype=torch.bfloat16, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AprielSSMHybridModel(\n",
       "  (embed_tokens): Embedding(131072, 4096)\n",
       "  (layers): ModuleList(\n",
       "    (0): AprielSSMDecoderLayer(\n",
       "      (mixer): DiscreteMamba2(\n",
       "        (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "        (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "        (act): Identity()\n",
       "        (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (1): AprielDecoderLayer(\n",
       "      (self_attn): AprielAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (2): AprielSSMDecoderLayer(\n",
       "      (mixer): DiscreteMamba2(\n",
       "        (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "        (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "        (act): Identity()\n",
       "        (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (3): AprielDecoderLayer(\n",
       "      (self_attn): AprielAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (4): AprielSSMDecoderLayer(\n",
       "      (mixer): DiscreteMamba2(\n",
       "        (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "        (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "        (act): Identity()\n",
       "        (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (5): AprielDecoderLayer(\n",
       "      (self_attn): AprielAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (6): AprielSSMDecoderLayer(\n",
       "      (mixer): DiscreteMamba2(\n",
       "        (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "        (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "        (act): Identity()\n",
       "        (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (7): AprielDecoderLayer(\n",
       "      (self_attn): AprielAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (8): AprielSSMDecoderLayer(\n",
       "      (mixer): DiscreteMamba2(\n",
       "        (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "        (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "        (act): Identity()\n",
       "        (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (9): AprielDecoderLayer(\n",
       "      (self_attn): AprielAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (10): AprielSSMDecoderLayer(\n",
       "      (mixer): DiscreteMamba2(\n",
       "        (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "        (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "        (act): Identity()\n",
       "        (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (11): AprielDecoderLayer(\n",
       "      (self_attn): AprielAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (12): AprielSSMDecoderLayer(\n",
       "      (mixer): DiscreteMamba2(\n",
       "        (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "        (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "        (act): Identity()\n",
       "        (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (13): AprielDecoderLayer(\n",
       "      (self_attn): AprielAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (14): AprielSSMDecoderLayer(\n",
       "      (mixer): DiscreteMamba2(\n",
       "        (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "        (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "        (act): Identity()\n",
       "        (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (15): AprielDecoderLayer(\n",
       "      (self_attn): AprielAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (16): AprielSSMDecoderLayer(\n",
       "      (mixer): DiscreteMamba2(\n",
       "        (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "        (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "        (act): Identity()\n",
       "        (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (17): AprielDecoderLayer(\n",
       "      (self_attn): AprielAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (18): AprielSSMDecoderLayer(\n",
       "      (mixer): DiscreteMamba2(\n",
       "        (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "        (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "        (act): Identity()\n",
       "        (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (19): AprielDecoderLayer(\n",
       "      (self_attn): AprielAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (20): AprielSSMDecoderLayer(\n",
       "      (mixer): DiscreteMamba2(\n",
       "        (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "        (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "        (act): Identity()\n",
       "        (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (21): AprielDecoderLayer(\n",
       "      (self_attn): AprielAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (22): AprielSSMDecoderLayer(\n",
       "      (mixer): DiscreteMamba2(\n",
       "        (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "        (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "        (act): Identity()\n",
       "        (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (23): AprielDecoderLayer(\n",
       "      (self_attn): AprielAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (24): AprielSSMDecoderLayer(\n",
       "      (mixer): DiscreteMamba2(\n",
       "        (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "        (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "        (act): Identity()\n",
       "        (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (25): AprielDecoderLayer(\n",
       "      (self_attn): AprielAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (26): AprielSSMDecoderLayer(\n",
       "      (mixer): DiscreteMamba2(\n",
       "        (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "        (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "        (act): Identity()\n",
       "        (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "    (27): AprielDecoderLayer(\n",
       "      (self_attn): AprielAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "      )\n",
       "      (mlp): AprielMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "        (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "    )\n",
       "  )\n",
       "  (norm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "  (rotary_emb): AprielRotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mamba in LLama pure SSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mamba_ssm import MambaLMHeadModel\n",
    "from mamba_ssm.models.config_mamba import MambaConfig\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "from fast_llm.models.ssm.external.aperiel_ssm.configuration_ssm_apriel import AprielSSMConfig\n",
    "from fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel import AprielSSMForCausalLM\n",
    "from fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel import AprielDecoderLayer as AprielSSMDecoderLayer\n",
    "from transformers.cache_utils import StaticCache\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# make sure the code changes reflected without reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  9.03it/s]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"ServiceNow-AI/Apriel-5B-Instruct\"\n",
    "device = \"cuda\"\n",
    "# checkpoint = \"/mnt/checkpoints/upstream/Apriel-5B-Instruct-llamafied\"\n",
    "config = AutoConfig.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "apriel_model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "apriel_state_dict = apriel_model.state_dict()\n",
    "apriel_model.to(device).to(dtype=torch.bfloat16)\n",
    "apriel_state_dict = apriel_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AprielSSMConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m apriel_ssm_config \u001b[38;5;241m=\u001b[39m \u001b[43mAprielSSMConfig\u001b[49m(vocab_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size, \n\u001b[1;32m      2\u001b[0m                                     hidden_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m      3\u001b[0m                                     intermediate_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mintermediate_size,\n\u001b[1;32m      4\u001b[0m                                     num_hidden_layers\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers,\n\u001b[1;32m      5\u001b[0m                                     hidden_act\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhidden_act,\n\u001b[1;32m      6\u001b[0m                                     initializer_range\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39minitializer_range,\n\u001b[1;32m      7\u001b[0m                                     use_cache\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache,\n\u001b[1;32m      8\u001b[0m                                     mlp_bias\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmlp_bias,\n\u001b[1;32m      9\u001b[0m                                     tie_word_embeddings\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtie_word_embeddings,\n\u001b[1;32m     10\u001b[0m                                     pad_token_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id,\n\u001b[1;32m     11\u001b[0m                                     bos_token_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbos_token_id,\n\u001b[1;32m     12\u001b[0m                                     eos_token_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[1;32m     13\u001b[0m                                     rms_norm_eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps,\n\u001b[1;32m     14\u001b[0m                                     ssm_cfg\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     15\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m     16\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_v_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m24\u001b[39m,\n\u001b[1;32m     17\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_qk_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m24\u001b[39m,\n\u001b[1;32m     18\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     19\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     20\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_inner\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m24\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     23\u001b[0m                                     })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AprielSSMConfig' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "apriel_ssm_config = AprielSSMConfig(vocab_size=config.vocab_size, \n",
    "                                    hidden_size=config.hidden_size,\n",
    "                                    intermediate_size=config.intermediate_size,\n",
    "                                    num_hidden_layers=config.num_hidden_layers,\n",
    "                                    hidden_act=config.hidden_act,\n",
    "                                    initializer_range=config.initializer_range,\n",
    "                                    use_cache=config.use_cache,\n",
    "                                    mlp_bias=config.mlp_bias,\n",
    "                                    tie_word_embeddings=config.tie_word_embeddings,\n",
    "                                    pad_token_id=config.pad_token_id,\n",
    "                                    bos_token_id=config.bos_token_id,\n",
    "                                    eos_token_id=config.eos_token_id,\n",
    "                                    rms_norm_eps=config.rms_norm_eps,\n",
    "                                    ssm_cfg={\n",
    "                                        \"d_state\": 64,\n",
    "                                        \"n_v_heads\": 24,\n",
    "                                        \"n_qk_heads\": 24,\n",
    "                                        \"expand\": 1,\n",
    "                                        \"chunk_size\": 128,\n",
    "                                        \"activation\": \"identity\",\n",
    "                                        \"bias\": False,\n",
    "                                        \"d_inner\": 24 * 128,\n",
    "                                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "apriel_ssm = AprielSSMForCausalLM(apriel_ssm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AprielSSMForCausalLM(\n",
       "  (model): AprielSSMModel(\n",
       "    (embed_tokens): Embedding(131072, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x AprielDecoderLayer(\n",
       "        (mixer): DiscreteMamba2(\n",
       "          (in_proj): Linear(in_features=4096, out_features=9240, bias=False)\n",
       "          (conv1d): Conv1d(6144, 6144, kernel_size=(4,), stride=(1,), padding=(3,), groups=6144)\n",
       "          (act): Identity()\n",
       "          (out_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): AprielMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): AprielRMSNorm((4096,), eps=1e-05)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=131072, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriel_ssm.to(device).to(dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['model.layers.0.mixer.z_bias', 'model.layers.0.mixer.D', 'model.layers.0.mixer.in_proj.weight', 'model.layers.0.mixer.conv1d.weight', 'model.layers.0.mixer.conv1d.bias', 'model.layers.0.mixer.out_proj.weight', 'model.layers.1.mixer.z_bias', 'model.layers.1.mixer.D', 'model.layers.1.mixer.in_proj.weight', 'model.layers.1.mixer.conv1d.weight', 'model.layers.1.mixer.conv1d.bias', 'model.layers.1.mixer.out_proj.weight', 'model.layers.2.mixer.z_bias', 'model.layers.2.mixer.D', 'model.layers.2.mixer.in_proj.weight', 'model.layers.2.mixer.conv1d.weight', 'model.layers.2.mixer.conv1d.bias', 'model.layers.2.mixer.out_proj.weight', 'model.layers.3.mixer.z_bias', 'model.layers.3.mixer.D', 'model.layers.3.mixer.in_proj.weight', 'model.layers.3.mixer.conv1d.weight', 'model.layers.3.mixer.conv1d.bias', 'model.layers.3.mixer.out_proj.weight', 'model.layers.4.mixer.z_bias', 'model.layers.4.mixer.D', 'model.layers.4.mixer.in_proj.weight', 'model.layers.4.mixer.conv1d.weight', 'model.layers.4.mixer.conv1d.bias', 'model.layers.4.mixer.out_proj.weight', 'model.layers.5.mixer.z_bias', 'model.layers.5.mixer.D', 'model.layers.5.mixer.in_proj.weight', 'model.layers.5.mixer.conv1d.weight', 'model.layers.5.mixer.conv1d.bias', 'model.layers.5.mixer.out_proj.weight', 'model.layers.6.mixer.z_bias', 'model.layers.6.mixer.D', 'model.layers.6.mixer.in_proj.weight', 'model.layers.6.mixer.conv1d.weight', 'model.layers.6.mixer.conv1d.bias', 'model.layers.6.mixer.out_proj.weight', 'model.layers.7.mixer.z_bias', 'model.layers.7.mixer.D', 'model.layers.7.mixer.in_proj.weight', 'model.layers.7.mixer.conv1d.weight', 'model.layers.7.mixer.conv1d.bias', 'model.layers.7.mixer.out_proj.weight', 'model.layers.8.mixer.z_bias', 'model.layers.8.mixer.D', 'model.layers.8.mixer.in_proj.weight', 'model.layers.8.mixer.conv1d.weight', 'model.layers.8.mixer.conv1d.bias', 'model.layers.8.mixer.out_proj.weight', 'model.layers.9.mixer.z_bias', 'model.layers.9.mixer.D', 'model.layers.9.mixer.in_proj.weight', 'model.layers.9.mixer.conv1d.weight', 'model.layers.9.mixer.conv1d.bias', 'model.layers.9.mixer.out_proj.weight', 'model.layers.10.mixer.z_bias', 'model.layers.10.mixer.D', 'model.layers.10.mixer.in_proj.weight', 'model.layers.10.mixer.conv1d.weight', 'model.layers.10.mixer.conv1d.bias', 'model.layers.10.mixer.out_proj.weight', 'model.layers.11.mixer.z_bias', 'model.layers.11.mixer.D', 'model.layers.11.mixer.in_proj.weight', 'model.layers.11.mixer.conv1d.weight', 'model.layers.11.mixer.conv1d.bias', 'model.layers.11.mixer.out_proj.weight', 'model.layers.12.mixer.z_bias', 'model.layers.12.mixer.D', 'model.layers.12.mixer.in_proj.weight', 'model.layers.12.mixer.conv1d.weight', 'model.layers.12.mixer.conv1d.bias', 'model.layers.12.mixer.out_proj.weight', 'model.layers.13.mixer.z_bias', 'model.layers.13.mixer.D', 'model.layers.13.mixer.in_proj.weight', 'model.layers.13.mixer.conv1d.weight', 'model.layers.13.mixer.conv1d.bias', 'model.layers.13.mixer.out_proj.weight', 'model.layers.14.mixer.z_bias', 'model.layers.14.mixer.D', 'model.layers.14.mixer.in_proj.weight', 'model.layers.14.mixer.conv1d.weight', 'model.layers.14.mixer.conv1d.bias', 'model.layers.14.mixer.out_proj.weight', 'model.layers.15.mixer.z_bias', 'model.layers.15.mixer.D', 'model.layers.15.mixer.in_proj.weight', 'model.layers.15.mixer.conv1d.weight', 'model.layers.15.mixer.conv1d.bias', 'model.layers.15.mixer.out_proj.weight', 'model.layers.16.mixer.z_bias', 'model.layers.16.mixer.D', 'model.layers.16.mixer.in_proj.weight', 'model.layers.16.mixer.conv1d.weight', 'model.layers.16.mixer.conv1d.bias', 'model.layers.16.mixer.out_proj.weight', 'model.layers.17.mixer.z_bias', 'model.layers.17.mixer.D', 'model.layers.17.mixer.in_proj.weight', 'model.layers.17.mixer.conv1d.weight', 'model.layers.17.mixer.conv1d.bias', 'model.layers.17.mixer.out_proj.weight', 'model.layers.18.mixer.z_bias', 'model.layers.18.mixer.D', 'model.layers.18.mixer.in_proj.weight', 'model.layers.18.mixer.conv1d.weight', 'model.layers.18.mixer.conv1d.bias', 'model.layers.18.mixer.out_proj.weight', 'model.layers.19.mixer.z_bias', 'model.layers.19.mixer.D', 'model.layers.19.mixer.in_proj.weight', 'model.layers.19.mixer.conv1d.weight', 'model.layers.19.mixer.conv1d.bias', 'model.layers.19.mixer.out_proj.weight', 'model.layers.20.mixer.z_bias', 'model.layers.20.mixer.D', 'model.layers.20.mixer.in_proj.weight', 'model.layers.20.mixer.conv1d.weight', 'model.layers.20.mixer.conv1d.bias', 'model.layers.20.mixer.out_proj.weight', 'model.layers.21.mixer.z_bias', 'model.layers.21.mixer.D', 'model.layers.21.mixer.in_proj.weight', 'model.layers.21.mixer.conv1d.weight', 'model.layers.21.mixer.conv1d.bias', 'model.layers.21.mixer.out_proj.weight', 'model.layers.22.mixer.z_bias', 'model.layers.22.mixer.D', 'model.layers.22.mixer.in_proj.weight', 'model.layers.22.mixer.conv1d.weight', 'model.layers.22.mixer.conv1d.bias', 'model.layers.22.mixer.out_proj.weight', 'model.layers.23.mixer.z_bias', 'model.layers.23.mixer.D', 'model.layers.23.mixer.in_proj.weight', 'model.layers.23.mixer.conv1d.weight', 'model.layers.23.mixer.conv1d.bias', 'model.layers.23.mixer.out_proj.weight', 'model.layers.24.mixer.z_bias', 'model.layers.24.mixer.D', 'model.layers.24.mixer.in_proj.weight', 'model.layers.24.mixer.conv1d.weight', 'model.layers.24.mixer.conv1d.bias', 'model.layers.24.mixer.out_proj.weight', 'model.layers.25.mixer.z_bias', 'model.layers.25.mixer.D', 'model.layers.25.mixer.in_proj.weight', 'model.layers.25.mixer.conv1d.weight', 'model.layers.25.mixer.conv1d.bias', 'model.layers.25.mixer.out_proj.weight', 'model.layers.26.mixer.z_bias', 'model.layers.26.mixer.D', 'model.layers.26.mixer.in_proj.weight', 'model.layers.26.mixer.conv1d.weight', 'model.layers.26.mixer.conv1d.bias', 'model.layers.26.mixer.out_proj.weight', 'model.layers.27.mixer.z_bias', 'model.layers.27.mixer.D', 'model.layers.27.mixer.in_proj.weight', 'model.layers.27.mixer.conv1d.weight', 'model.layers.27.mixer.conv1d.bias', 'model.layers.27.mixer.out_proj.weight'], unexpected_keys=['model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.27.self_attn.o_proj.weight'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "apriel_ssm.load_state_dict(apriel_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "1 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "2 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "3 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "4 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "5 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "6 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "7 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "8 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "9 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "10 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "11 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "12 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "13 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "14 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "15 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "16 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "17 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "18 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "19 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "20 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "21 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "22 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "23 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "24 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "25 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "26 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n",
      "27 <class 'fast_llm.models.ssm.external.aperiel_ssm.modeling_ssm_apriel.AprielDecoderLayer'>\n",
      "Innitiating SSM layer\n"
     ]
    }
   ],
   "source": [
    "mil_innit(apriel_ssm, apriel_model, AprielSSMDecoderLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toolkit/.local/lib/python3.12/site-packages/transformers/modeling_utils.py:2714: UserWarning: `save_config` is deprecated and will be removed in v5 of Transformers. Use `is_main_process` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "apriel_ssm.save_pretrained(\"/mnt/checkpoints/ssm/apriel_ssm_instruct_init_mambainlama\", save_config=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 4096])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\" #if torch.cuda.is_available() else \"cpu\"\n",
    "input_ids = torch.randint(0, 32000, (1, 128), dtype=torch.long, device=device)\n",
    "batch_size = 1\n",
    "max_length = 128\n",
    "state = SimpleNamespace()\n",
    "state.key_value_memory_dict = hybrid_apriel_model.allocate_inference_cache(batch_size, max_length, dtype=torch.bfloat16)\n",
    "state.batch_size = batch_size\n",
    "state.seqlen_offset = 0\n",
    "static_inputs = {\"inference_params\": state,\n",
    "        \"input_ids\": input_ids,\n",
    "        \"use_cache\": True,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_apriel_model.to(device).to(dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hybrid_apriel_model.forward(**static_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_xb = config.num_key_value_heads * config.head_dim\n",
    "ssm_layers = [2,4,8]\n",
    "attn_layers = [i for i in range(config.num_hidden_layers) if i not in ssm_layers]\n",
    "model_name = \"ServiceNow-AI/Apriel-5B-Instruct\"\n",
    "ngroups = config.num_attention_heads # n heads\n",
    "d_inner = config.head_dim * config.num_attention_heads\n",
    "headdim = 128 # d_state\n",
    "d_state = config.head_dim\n",
    "d_model = config.hidden_size    \n",
    "assert d_inner == ngroups * d_state\n",
    "\n",
    "mamba_config = AprielSSMConfig(\n",
    "    ssm_cfg={\n",
    "            \"d_state\": 64,\n",
    "            \"n_v_heads\": 24,\n",
    "            \"n_qk_heads\": 24,\n",
    "            \"expand\": 1,\n",
    "            \"chunk_size\": 128,\n",
    "            \"activation\": \"identity\",\n",
    "            \"bias\": False,\n",
    "            \"d_inner\": 24 * headdim,  # num_heads * head_dim\n",
    "        },\n",
    "    vocab_size=config.vocab_size, \n",
    "    hidden_size=config.hidden_size,\n",
    "    intermediate_size=config.intermediate_size,\n",
    "    num_hidden_layers=config.num_hidden_layers,\n",
    "    hidden_act=config.hidden_act,\n",
    "    initializer_range=config.initializer_range,\n",
    "    use_cache=config.use_cache,\n",
    "    mlp_bias=config.mlp_bias,\n",
    "    tie_word_embeddings=config.tie_word_embeddings,\n",
    "    pad_token_id=config.pad_token_id,\n",
    "    bos_token_id=config.bos_token_id,\n",
    "    eos_token_id=config.eos_token_id,\n",
    "    head_dim=config.head_dim,\n",
    "    rms_norm_eps=config.rms_norm_eps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = MambaTransformerHybridModelWrapper.init_distillation(None, model_name, \n",
    "                                                                     mamba_config, \n",
    "                                                                     attn_layers=attn_layers, \n",
    "                                                                     init_with_kqvo=True, \n",
    "                                                                     attn_implementation=\"flash_attention_2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cartesia_pytorch.Llamba.llamba import LlambaLMHeadModel, LlambaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llamba \u001b[38;5;241m=\u001b[39m \u001b[43mLlambaLMHeadModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/checkpoints_fml/pretrained_models/llamba-1b/mohawk_distributed_stage2_from_final/checkpoints/mohawk_step9000\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m llamba\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:553\u001b[0m, in \u001b[0;36mModelHubMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_hub_mixin_inject_config \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m    551\u001b[0m         model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 553\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# Implicitly set the config as instance attribute if not already set by the class\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# This way `config` will be available when calling `save_pretrained` or `push_to_hub`.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mgetattr\u001b[39m(instance, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hub_mixin_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, {})):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/huggingface_hub/hub_mixin.py:774\u001b[0m, in \u001b[0;36mPyTorchModelHubMixin._from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_from_pretrained\u001b[39m(\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m    772\u001b[0m ):\n\u001b[1;32m    773\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 774\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(model_id):\n\u001b[1;32m    776\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading weights from local directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dev/edge/cartesia-pytorch/cartesia_pytorch/Llamba/llamba.py:52\u001b[0m, in \u001b[0;36mLlambaLMHeadModel.__init__\u001b[0;34m(self, config, initializer_cfg, device, dtype, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m vocab_size\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Mixer model\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone \u001b[38;5;241m=\u001b[39m \u001b[43mMixerModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# LM head\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtie_embeddings:\n",
      "File \u001b[0;32m~/dev/edge/cartesia-pytorch/cartesia_pytorch/Llamba/llamba.py:142\u001b[0m, in \u001b[0;36mMixerModel.__init__\u001b[0;34m(self, input_size, config, device, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[1;32m    145\u001b[0m     [\n\u001b[1;32m    146\u001b[0m         Block(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m     ]\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layernorm \u001b[38;5;241m=\u001b[39m LlamaRMSNorm(\n\u001b[1;32m    156\u001b[0m     hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39md_model,\n\u001b[1;32m    157\u001b[0m     eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnorm_epsilon,\n\u001b[1;32m    158\u001b[0m     factory_kwargs\u001b[38;5;241m=\u001b[39mfactory_kwargs,\n\u001b[1;32m    159\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/torch/nn/modules/sparse.py:144\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq \u001b[38;5;241m=\u001b[39m scale_grad_by_freq\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    145\u001b[0m                             requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m _freeze)\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_parameters()\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/torch/cuda/__init__.py:314\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    313\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 314\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    318\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "llamba = LlambaLMHeadModel.from_pretrained(\"/mnt/checkpoints_fml/pretrained_models/llamba-1b/mohawk_distributed_stage2_from_final/checkpoints/mohawk_step9000\",\n",
    "                                           use_safetensors=False,\n",
    "                                           torch_dtype=torch.bfloat16,\n",
    "                                           trust_remote_code=True,\n",
    "                                           device=\"cuda\")\n",
    "\n",
    "llamba.to(device).to(dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cartesia_pytorch.Llamba.llamba import LlambaLMHeadModel, LlambaConfig\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/checkpoints_fml/pretrained_models/llamba-1b/mohawk_distributed_stage2_from_final/checkpoints/mohawk_final/pytorch_model.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/torch/serialization.py:1097\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1096\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1097\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1105\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/torch/serialization.py:1525\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# Needed for tensors where storage device and rebuild tensor device are\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# not connected (wrapper subclasses and tensors rebuilt using numpy)\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1525\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location\n\u001b[1;32m   1528\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/torch/serialization.py:1492\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1491\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1492\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/torch/serialization.py:1466\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1461\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1466\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1467\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1468\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1471\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/torch/serialization.py:414\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 414\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/torch/serialization.py:391\u001b[0m, in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    389\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[0;32m--> 391\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/torch/serialization.py:364\u001b[0m, in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    362\u001b[0m     device_index \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_available\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    365\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    366\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    367\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    368\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice_count\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    370\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "state_dict = torch.load(\"/mnt/checkpoints_fml/pretrained_models/llamba-1b/mohawk_distributed_stage2_from_final/checkpoints/mohawk_final/pytorch_model.bin\",  weights_only=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open(\"/mnt/checkpoints_fml/pretrained_models/llamba-1b/mohawk_distributed_stage2_from_final/checkpoints/mohawk_final/config.json\"))\n",
    "llamba = LlambaLMHeadModel(LlambaConfig(**config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LlambaLMHeadModel:\n\tMissing key(s) in state_dict: \"backbone.embedding.weight\", \"backbone.layers.0.mixer.z_bias\", \"backbone.layers.0.mixer.D\", \"backbone.layers.0.mixer.in_proj.weight\", \"backbone.layers.0.mixer.conv1d.weight\", \"backbone.layers.0.mixer.conv1d.bias\", \"backbone.layers.0.mixer.out_proj.weight\", \"backbone.layers.0.input_layernorm.weight\", \"backbone.layers.0.post_attention_layernorm.weight\", \"backbone.layers.0.mlp.gate_proj.weight\", \"backbone.layers.0.mlp.up_proj.weight\", \"backbone.layers.0.mlp.down_proj.weight\", \"backbone.layers.1.mixer.z_bias\", \"backbone.layers.1.mixer.D\", \"backbone.layers.1.mixer.in_proj.weight\", \"backbone.layers.1.mixer.conv1d.weight\", \"backbone.layers.1.mixer.conv1d.bias\", \"backbone.layers.1.mixer.out_proj.weight\", \"backbone.layers.1.input_layernorm.weight\", \"backbone.layers.1.post_attention_layernorm.weight\", \"backbone.layers.1.mlp.gate_proj.weight\", \"backbone.layers.1.mlp.up_proj.weight\", \"backbone.layers.1.mlp.down_proj.weight\", \"backbone.layers.2.mixer.z_bias\", \"backbone.layers.2.mixer.D\", \"backbone.layers.2.mixer.in_proj.weight\", \"backbone.layers.2.mixer.conv1d.weight\", \"backbone.layers.2.mixer.conv1d.bias\", \"backbone.layers.2.mixer.out_proj.weight\", \"backbone.layers.2.input_layernorm.weight\", \"backbone.layers.2.post_attention_layernorm.weight\", \"backbone.layers.2.mlp.gate_proj.weight\", \"backbone.layers.2.mlp.up_proj.weight\", \"backbone.layers.2.mlp.down_proj.weight\", \"backbone.layers.3.mixer.z_bias\", \"backbone.layers.3.mixer.D\", \"backbone.layers.3.mixer.in_proj.weight\", \"backbone.layers.3.mixer.conv1d.weight\", \"backbone.layers.3.mixer.conv1d.bias\", \"backbone.layers.3.mixer.out_proj.weight\", \"backbone.layers.3.input_layernorm.weight\", \"backbone.layers.3.post_attention_layernorm.weight\", \"backbone.layers.3.mlp.gate_proj.weight\", \"backbone.layers.3.mlp.up_proj.weight\", \"backbone.layers.3.mlp.down_proj.weight\", \"backbone.layers.4.mixer.z_bias\", \"backbone.layers.4.mixer.D\", \"backbone.layers.4.mixer.in_proj.weight\", \"backbone.layers.4.mixer.conv1d.weight\", \"backbone.layers.4.mixer.conv1d.bias\", \"backbone.layers.4.mixer.out_proj.weight\", \"backbone.layers.4.input_layernorm.weight\", \"backbone.layers.4.post_attention_layernorm.weight\", \"backbone.layers.4.mlp.gate_proj.weight\", \"backbone.layers.4.mlp.up_proj.weight\", \"backbone.layers.4.mlp.down_proj.weight\", \"backbone.layers.5.mixer.z_bias\", \"backbone.layers.5.mixer.D\", \"backbone.layers.5.mixer.in_proj.weight\", \"backbone.layers.5.mixer.conv1d.weight\", \"backbone.layers.5.mixer.conv1d.bias\", \"backbone.layers.5.mixer.out_proj.weight\", \"backbone.layers.5.input_layernorm.weight\", \"backbone.layers.5.post_attention_layernorm.weight\", \"backbone.layers.5.mlp.gate_proj.weight\", \"backbone.layers.5.mlp.up_proj.weight\", \"backbone.layers.5.mlp.down_proj.weight\", \"backbone.layers.6.mixer.z_bias\", \"backbone.layers.6.mixer.D\", \"backbone.layers.6.mixer.in_proj.weight\", \"backbone.layers.6.mixer.conv1d.weight\", \"backbone.layers.6.mixer.conv1d.bias\", \"backbone.layers.6.mixer.out_proj.weight\", \"backbone.layers.6.input_layernorm.weight\", \"backbone.layers.6.post_attention_layernorm.weight\", \"backbone.layers.6.mlp.gate_proj.weight\", \"backbone.layers.6.mlp.up_proj.weight\", \"backbone.layers.6.mlp.down_proj.weight\", \"backbone.layers.7.mixer.z_bias\", \"backbone.layers.7.mixer.D\", \"backbone.layers.7.mixer.in_proj.weight\", \"backbone.layers.7.mixer.conv1d.weight\", \"backbone.layers.7.mixer.conv1d.bias\", \"backbone.layers.7.mixer.out_proj.weight\", \"backbone.layers.7.input_layernorm.weight\", \"backbone.layers.7.post_attention_layernorm.weight\", \"backbone.layers.7.mlp.gate_proj.weight\", \"backbone.layers.7.mlp.up_proj.weight\", \"backbone.layers.7.mlp.down_proj.weight\", \"backbone.layers.8.mixer.z_bias\", \"backbone.layers.8.mixer.D\", \"backbone.layers.8.mixer.in_proj.weight\", \"backbone.layers.8.mixer.conv1d.weight\", \"backbone.layers.8.mixer.conv1d.bias\", \"backbone.layers.8.mixer.out_proj.weight\", \"backbone.layers.8.input_layernorm.weight\", \"backbone.layers.8.post_attention_layernorm.weight\", \"backbone.layers.8.mlp.gate_proj.weight\", \"backbone.layers.8.mlp.up_proj.weight\", \"backbone.layers.8.mlp.down_proj.weight\", \"backbone.layers.9.mixer.z_bias\", \"backbone.layers.9.mixer.D\", \"backbone.layers.9.mixer.in_proj.weight\", \"backbone.layers.9.mixer.conv1d.weight\", \"backbone.layers.9.mixer.conv1d.bias\", \"backbone.layers.9.mixer.out_proj.weight\", \"backbone.layers.9.input_layernorm.weight\", \"backbone.layers.9.post_attention_layernorm.weight\", \"backbone.layers.9.mlp.gate_proj.weight\", \"backbone.layers.9.mlp.up_proj.weight\", \"backbone.layers.9.mlp.down_proj.weight\", \"backbone.layers.10.mixer.z_bias\", \"backbone.layers.10.mixer.D\", \"backbone.layers.10.mixer.in_proj.weight\", \"backbone.layers.10.mixer.conv1d.weight\", \"backbone.layers.10.mixer.conv1d.bias\", \"backbone.layers.10.mixer.out_proj.weight\", \"backbone.layers.10.input_layernorm.weight\", \"backbone.layers.10.post_attention_layernorm.weight\", \"backbone.layers.10.mlp.gate_proj.weight\", \"backbone.layers.10.mlp.up_proj.weight\", \"backbone.layers.10.mlp.down_proj.weight\", \"backbone.layers.11.mixer.z_bias\", \"backbone.layers.11.mixer.D\", \"backbone.layers.11.mixer.in_proj.weight\", \"backbone.layers.11.mixer.conv1d.weight\", \"backbone.layers.11.mixer.conv1d.bias\", \"backbone.layers.11.mixer.out_proj.weight\", \"backbone.layers.11.input_layernorm.weight\", \"backbone.layers.11.post_attention_layernorm.weight\", \"backbone.layers.11.mlp.gate_proj.weight\", \"backbone.layers.11.mlp.up_proj.weight\", \"backbone.layers.11.mlp.down_proj.weight\", \"backbone.layers.12.mixer.z_bias\", \"backbone.layers.12.mixer.D\", \"backbone.layers.12.mixer.in_proj.weight\", \"backbone.layers.12.mixer.conv1d.weight\", \"backbone.layers.12.mixer.conv1d.bias\", \"backbone.layers.12.mixer.out_proj.weight\", \"backbone.layers.12.input_layernorm.weight\", \"backbone.layers.12.post_attention_layernorm.weight\", \"backbone.layers.12.mlp.gate_proj.weight\", \"backbone.layers.12.mlp.up_proj.weight\", \"backbone.layers.12.mlp.down_proj.weight\", \"backbone.layers.13.mixer.z_bias\", \"backbone.layers.13.mixer.D\", \"backbone.layers.13.mixer.in_proj.weight\", \"backbone.layers.13.mixer.conv1d.weight\", \"backbone.layers.13.mixer.conv1d.bias\", \"backbone.layers.13.mixer.out_proj.weight\", \"backbone.layers.13.input_layernorm.weight\", \"backbone.layers.13.post_attention_layernorm.weight\", \"backbone.layers.13.mlp.gate_proj.weight\", \"backbone.layers.13.mlp.up_proj.weight\", \"backbone.layers.13.mlp.down_proj.weight\", \"backbone.layers.14.mixer.z_bias\", \"backbone.layers.14.mixer.D\", \"backbone.layers.14.mixer.in_proj.weight\", \"backbone.layers.14.mixer.conv1d.weight\", \"backbone.layers.14.mixer.conv1d.bias\", \"backbone.layers.14.mixer.out_proj.weight\", \"backbone.layers.14.input_layernorm.weight\", \"backbone.layers.14.post_attention_layernorm.weight\", \"backbone.layers.14.mlp.gate_proj.weight\", \"backbone.layers.14.mlp.up_proj.weight\", \"backbone.layers.14.mlp.down_proj.weight\", \"backbone.layers.15.mixer.z_bias\", \"backbone.layers.15.mixer.D\", \"backbone.layers.15.mixer.in_proj.weight\", \"backbone.layers.15.mixer.conv1d.weight\", \"backbone.layers.15.mixer.conv1d.bias\", \"backbone.layers.15.mixer.out_proj.weight\", \"backbone.layers.15.input_layernorm.weight\", \"backbone.layers.15.post_attention_layernorm.weight\", \"backbone.layers.15.mlp.gate_proj.weight\", \"backbone.layers.15.mlp.up_proj.weight\", \"backbone.layers.15.mlp.down_proj.weight\", \"backbone.final_layernorm.weight\". \n\tUnexpected key(s) in state_dict: \"model.embed_tokens.weight\", \"model.layers.0.self_attn.q_proj.weight\", \"model.layers.0.self_attn.k_proj.weight\", \"model.layers.0.self_attn.v_proj.weight\", \"model.layers.0.self_attn.o_proj.weight\", \"model.layers.0.mlp.gate_proj.weight\", \"model.layers.0.mlp.up_proj.weight\", \"model.layers.0.mlp.down_proj.weight\", \"model.layers.0.input_layernorm.weight\", \"model.layers.0.post_attention_layernorm.weight\", \"model.layers.1.self_attn.q_proj.weight\", \"model.layers.1.self_attn.k_proj.weight\", \"model.layers.1.self_attn.v_proj.weight\", \"model.layers.1.self_attn.o_proj.weight\", \"model.layers.1.mlp.gate_proj.weight\", \"model.layers.1.mlp.up_proj.weight\", \"model.layers.1.mlp.down_proj.weight\", \"model.layers.1.input_layernorm.weight\", \"model.layers.1.post_attention_layernorm.weight\", \"model.layers.2.self_attn.q_proj.weight\", \"model.layers.2.self_attn.k_proj.weight\", \"model.layers.2.self_attn.v_proj.weight\", \"model.layers.2.self_attn.o_proj.weight\", \"model.layers.2.mlp.gate_proj.weight\", \"model.layers.2.mlp.up_proj.weight\", \"model.layers.2.mlp.down_proj.weight\", \"model.layers.2.input_layernorm.weight\", \"model.layers.2.post_attention_layernorm.weight\", \"model.layers.3.self_attn.q_proj.weight\", \"model.layers.3.self_attn.k_proj.weight\", \"model.layers.3.self_attn.v_proj.weight\", \"model.layers.3.self_attn.o_proj.weight\", \"model.layers.3.mlp.gate_proj.weight\", \"model.layers.3.mlp.up_proj.weight\", \"model.layers.3.mlp.down_proj.weight\", \"model.layers.3.input_layernorm.weight\", \"model.layers.3.post_attention_layernorm.weight\", \"model.layers.4.self_attn.q_proj.weight\", \"model.layers.4.self_attn.k_proj.weight\", \"model.layers.4.self_attn.v_proj.weight\", \"model.layers.4.self_attn.o_proj.weight\", \"model.layers.4.mlp.gate_proj.weight\", \"model.layers.4.mlp.up_proj.weight\", \"model.layers.4.mlp.down_proj.weight\", \"model.layers.4.input_layernorm.weight\", \"model.layers.4.post_attention_layernorm.weight\", \"model.layers.5.self_attn.q_proj.weight\", \"model.layers.5.self_attn.k_proj.weight\", \"model.layers.5.self_attn.v_proj.weight\", \"model.layers.5.self_attn.o_proj.weight\", \"model.layers.5.mlp.gate_proj.weight\", \"model.layers.5.mlp.up_proj.weight\", \"model.layers.5.mlp.down_proj.weight\", \"model.layers.5.input_layernorm.weight\", \"model.layers.5.post_attention_layernorm.weight\", \"model.layers.6.self_attn.q_proj.weight\", \"model.layers.6.self_attn.k_proj.weight\", \"model.layers.6.self_attn.v_proj.weight\", \"model.layers.6.self_attn.o_proj.weight\", \"model.layers.6.mlp.gate_proj.weight\", \"model.layers.6.mlp.up_proj.weight\", \"model.layers.6.mlp.down_proj.weight\", \"model.layers.6.input_layernorm.weight\", \"model.layers.6.post_attention_layernorm.weight\", \"model.layers.7.self_attn.q_proj.weight\", \"model.layers.7.self_attn.k_proj.weight\", \"model.layers.7.self_attn.v_proj.weight\", \"model.layers.7.self_attn.o_proj.weight\", \"model.layers.7.mlp.gate_proj.weight\", \"model.layers.7.mlp.up_proj.weight\", \"model.layers.7.mlp.down_proj.weight\", \"model.layers.7.input_layernorm.weight\", \"model.layers.7.post_attention_layernorm.weight\", \"model.layers.8.self_attn.q_proj.weight\", \"model.layers.8.self_attn.k_proj.weight\", \"model.layers.8.self_attn.v_proj.weight\", \"model.layers.8.self_attn.o_proj.weight\", \"model.layers.8.mlp.gate_proj.weight\", \"model.layers.8.mlp.up_proj.weight\", \"model.layers.8.mlp.down_proj.weight\", \"model.layers.8.input_layernorm.weight\", \"model.layers.8.post_attention_layernorm.weight\", \"model.layers.9.self_attn.q_proj.weight\", \"model.layers.9.self_attn.k_proj.weight\", \"model.layers.9.self_attn.v_proj.weight\", \"model.layers.9.self_attn.o_proj.weight\", \"model.layers.9.mlp.gate_proj.weight\", \"model.layers.9.mlp.up_proj.weight\", \"model.layers.9.mlp.down_proj.weight\", \"model.layers.9.input_layernorm.weight\", \"model.layers.9.post_attention_layernorm.weight\", \"model.layers.10.self_attn.q_proj.weight\", \"model.layers.10.self_attn.k_proj.weight\", \"model.layers.10.self_attn.v_proj.weight\", \"model.layers.10.self_attn.o_proj.weight\", \"model.layers.10.mlp.gate_proj.weight\", \"model.layers.10.mlp.up_proj.weight\", \"model.layers.10.mlp.down_proj.weight\", \"model.layers.10.input_layernorm.weight\", \"model.layers.10.post_attention_layernorm.weight\", \"model.layers.11.self_attn.q_proj.weight\", \"model.layers.11.self_attn.k_proj.weight\", \"model.layers.11.self_attn.v_proj.weight\", \"model.layers.11.self_attn.o_proj.weight\", \"model.layers.11.mlp.gate_proj.weight\", \"model.layers.11.mlp.up_proj.weight\", \"model.layers.11.mlp.down_proj.weight\", \"model.layers.11.input_layernorm.weight\", \"model.layers.11.post_attention_layernorm.weight\", \"model.layers.12.self_attn.q_proj.weight\", \"model.layers.12.self_attn.k_proj.weight\", \"model.layers.12.self_attn.v_proj.weight\", \"model.layers.12.self_attn.o_proj.weight\", \"model.layers.12.mlp.gate_proj.weight\", \"model.layers.12.mlp.up_proj.weight\", \"model.layers.12.mlp.down_proj.weight\", \"model.layers.12.input_layernorm.weight\", \"model.layers.12.post_attention_layernorm.weight\", \"model.layers.13.self_attn.q_proj.weight\", \"model.layers.13.self_attn.k_proj.weight\", \"model.layers.13.self_attn.v_proj.weight\", \"model.layers.13.self_attn.o_proj.weight\", \"model.layers.13.mlp.gate_proj.weight\", \"model.layers.13.mlp.up_proj.weight\", \"model.layers.13.mlp.down_proj.weight\", \"model.layers.13.input_layernorm.weight\", \"model.layers.13.post_attention_layernorm.weight\", \"model.layers.14.self_attn.q_proj.weight\", \"model.layers.14.self_attn.k_proj.weight\", \"model.layers.14.self_attn.v_proj.weight\", \"model.layers.14.self_attn.o_proj.weight\", \"model.layers.14.mlp.gate_proj.weight\", \"model.layers.14.mlp.up_proj.weight\", \"model.layers.14.mlp.down_proj.weight\", \"model.layers.14.input_layernorm.weight\", \"model.layers.14.post_attention_layernorm.weight\", \"model.layers.15.self_attn.q_proj.weight\", \"model.layers.15.self_attn.k_proj.weight\", \"model.layers.15.self_attn.v_proj.weight\", \"model.layers.15.self_attn.o_proj.weight\", \"model.layers.15.mlp.gate_proj.weight\", \"model.layers.15.mlp.up_proj.weight\", \"model.layers.15.mlp.down_proj.weight\", \"model.layers.15.input_layernorm.weight\", \"model.layers.15.post_attention_layernorm.weight\", \"model.norm.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mllamba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LlambaLMHeadModel:\n\tMissing key(s) in state_dict: \"backbone.embedding.weight\", \"backbone.layers.0.mixer.z_bias\", \"backbone.layers.0.mixer.D\", \"backbone.layers.0.mixer.in_proj.weight\", \"backbone.layers.0.mixer.conv1d.weight\", \"backbone.layers.0.mixer.conv1d.bias\", \"backbone.layers.0.mixer.out_proj.weight\", \"backbone.layers.0.input_layernorm.weight\", \"backbone.layers.0.post_attention_layernorm.weight\", \"backbone.layers.0.mlp.gate_proj.weight\", \"backbone.layers.0.mlp.up_proj.weight\", \"backbone.layers.0.mlp.down_proj.weight\", \"backbone.layers.1.mixer.z_bias\", \"backbone.layers.1.mixer.D\", \"backbone.layers.1.mixer.in_proj.weight\", \"backbone.layers.1.mixer.conv1d.weight\", \"backbone.layers.1.mixer.conv1d.bias\", \"backbone.layers.1.mixer.out_proj.weight\", \"backbone.layers.1.input_layernorm.weight\", \"backbone.layers.1.post_attention_layernorm.weight\", \"backbone.layers.1.mlp.gate_proj.weight\", \"backbone.layers.1.mlp.up_proj.weight\", \"backbone.layers.1.mlp.down_proj.weight\", \"backbone.layers.2.mixer.z_bias\", \"backbone.layers.2.mixer.D\", \"backbone.layers.2.mixer.in_proj.weight\", \"backbone.layers.2.mixer.conv1d.weight\", \"backbone.layers.2.mixer.conv1d.bias\", \"backbone.layers.2.mixer.out_proj.weight\", \"backbone.layers.2.input_layernorm.weight\", \"backbone.layers.2.post_attention_layernorm.weight\", \"backbone.layers.2.mlp.gate_proj.weight\", \"backbone.layers.2.mlp.up_proj.weight\", \"backbone.layers.2.mlp.down_proj.weight\", \"backbone.layers.3.mixer.z_bias\", \"backbone.layers.3.mixer.D\", \"backbone.layers.3.mixer.in_proj.weight\", \"backbone.layers.3.mixer.conv1d.weight\", \"backbone.layers.3.mixer.conv1d.bias\", \"backbone.layers.3.mixer.out_proj.weight\", \"backbone.layers.3.input_layernorm.weight\", \"backbone.layers.3.post_attention_layernorm.weight\", \"backbone.layers.3.mlp.gate_proj.weight\", \"backbone.layers.3.mlp.up_proj.weight\", \"backbone.layers.3.mlp.down_proj.weight\", \"backbone.layers.4.mixer.z_bias\", \"backbone.layers.4.mixer.D\", \"backbone.layers.4.mixer.in_proj.weight\", \"backbone.layers.4.mixer.conv1d.weight\", \"backbone.layers.4.mixer.conv1d.bias\", \"backbone.layers.4.mixer.out_proj.weight\", \"backbone.layers.4.input_layernorm.weight\", \"backbone.layers.4.post_attention_layernorm.weight\", \"backbone.layers.4.mlp.gate_proj.weight\", \"backbone.layers.4.mlp.up_proj.weight\", \"backbone.layers.4.mlp.down_proj.weight\", \"backbone.layers.5.mixer.z_bias\", \"backbone.layers.5.mixer.D\", \"backbone.layers.5.mixer.in_proj.weight\", \"backbone.layers.5.mixer.conv1d.weight\", \"backbone.layers.5.mixer.conv1d.bias\", \"backbone.layers.5.mixer.out_proj.weight\", \"backbone.layers.5.input_layernorm.weight\", \"backbone.layers.5.post_attention_layernorm.weight\", \"backbone.layers.5.mlp.gate_proj.weight\", \"backbone.layers.5.mlp.up_proj.weight\", \"backbone.layers.5.mlp.down_proj.weight\", \"backbone.layers.6.mixer.z_bias\", \"backbone.layers.6.mixer.D\", \"backbone.layers.6.mixer.in_proj.weight\", \"backbone.layers.6.mixer.conv1d.weight\", \"backbone.layers.6.mixer.conv1d.bias\", \"backbone.layers.6.mixer.out_proj.weight\", \"backbone.layers.6.input_layernorm.weight\", \"backbone.layers.6.post_attention_layernorm.weight\", \"backbone.layers.6.mlp.gate_proj.weight\", \"backbone.layers.6.mlp.up_proj.weight\", \"backbone.layers.6.mlp.down_proj.weight\", \"backbone.layers.7.mixer.z_bias\", \"backbone.layers.7.mixer.D\", \"backbone.layers.7.mixer.in_proj.weight\", \"backbone.layers.7.mixer.conv1d.weight\", \"backbone.layers.7.mixer.conv1d.bias\", \"backbone.layers.7.mixer.out_proj.weight\", \"backbone.layers.7.input_layernorm.weight\", \"backbone.layers.7.post_attention_layernorm.weight\", \"backbone.layers.7.mlp.gate_proj.weight\", \"backbone.layers.7.mlp.up_proj.weight\", \"backbone.layers.7.mlp.down_proj.weight\", \"backbone.layers.8.mixer.z_bias\", \"backbone.layers.8.mixer.D\", \"backbone.layers.8.mixer.in_proj.weight\", \"backbone.layers.8.mixer.conv1d.weight\", \"backbone.layers.8.mixer.conv1d.bias\", \"backbone.layers.8.mixer.out_proj.weight\", \"backbone.layers.8.input_layernorm.weight\", \"backbone.layers.8.post_attention_layernorm.weight\", \"backbone.layers.8.mlp.gate_proj.weight\", \"backbone.layers.8.mlp.up_proj.weight\", \"backbone.layers.8.mlp.down_proj.weight\", \"backbone.layers.9.mixer.z_bias\", \"backbone.layers.9.mixer.D\", \"backbone.layers.9.mixer.in_proj.weight\", \"backbone.layers.9.mixer.conv1d.weight\", \"backbone.layers.9.mixer.conv1d.bias\", \"backbone.layers.9.mixer.out_proj.weight\", \"backbone.layers.9.input_layernorm.weight\", \"backbone.layers.9.post_attention_layernorm.weight\", \"backbone.layers.9.mlp.gate_proj.weight\", \"backbone.layers.9.mlp.up_proj.weight\", \"backbone.layers.9.mlp.down_proj.weight\", \"backbone.layers.10.mixer.z_bias\", \"backbone.layers.10.mixer.D\", \"backbone.layers.10.mixer.in_proj.weight\", \"backbone.layers.10.mixer.conv1d.weight\", \"backbone.layers.10.mixer.conv1d.bias\", \"backbone.layers.10.mixer.out_proj.weight\", \"backbone.layers.10.input_layernorm.weight\", \"backbone.layers.10.post_attention_layernorm.weight\", \"backbone.layers.10.mlp.gate_proj.weight\", \"backbone.layers.10.mlp.up_proj.weight\", \"backbone.layers.10.mlp.down_proj.weight\", \"backbone.layers.11.mixer.z_bias\", \"backbone.layers.11.mixer.D\", \"backbone.layers.11.mixer.in_proj.weight\", \"backbone.layers.11.mixer.conv1d.weight\", \"backbone.layers.11.mixer.conv1d.bias\", \"backbone.layers.11.mixer.out_proj.weight\", \"backbone.layers.11.input_layernorm.weight\", \"backbone.layers.11.post_attention_layernorm.weight\", \"backbone.layers.11.mlp.gate_proj.weight\", \"backbone.layers.11.mlp.up_proj.weight\", \"backbone.layers.11.mlp.down_proj.weight\", \"backbone.layers.12.mixer.z_bias\", \"backbone.layers.12.mixer.D\", \"backbone.layers.12.mixer.in_proj.weight\", \"backbone.layers.12.mixer.conv1d.weight\", \"backbone.layers.12.mixer.conv1d.bias\", \"backbone.layers.12.mixer.out_proj.weight\", \"backbone.layers.12.input_layernorm.weight\", \"backbone.layers.12.post_attention_layernorm.weight\", \"backbone.layers.12.mlp.gate_proj.weight\", \"backbone.layers.12.mlp.up_proj.weight\", \"backbone.layers.12.mlp.down_proj.weight\", \"backbone.layers.13.mixer.z_bias\", \"backbone.layers.13.mixer.D\", \"backbone.layers.13.mixer.in_proj.weight\", \"backbone.layers.13.mixer.conv1d.weight\", \"backbone.layers.13.mixer.conv1d.bias\", \"backbone.layers.13.mixer.out_proj.weight\", \"backbone.layers.13.input_layernorm.weight\", \"backbone.layers.13.post_attention_layernorm.weight\", \"backbone.layers.13.mlp.gate_proj.weight\", \"backbone.layers.13.mlp.up_proj.weight\", \"backbone.layers.13.mlp.down_proj.weight\", \"backbone.layers.14.mixer.z_bias\", \"backbone.layers.14.mixer.D\", \"backbone.layers.14.mixer.in_proj.weight\", \"backbone.layers.14.mixer.conv1d.weight\", \"backbone.layers.14.mixer.conv1d.bias\", \"backbone.layers.14.mixer.out_proj.weight\", \"backbone.layers.14.input_layernorm.weight\", \"backbone.layers.14.post_attention_layernorm.weight\", \"backbone.layers.14.mlp.gate_proj.weight\", \"backbone.layers.14.mlp.up_proj.weight\", \"backbone.layers.14.mlp.down_proj.weight\", \"backbone.layers.15.mixer.z_bias\", \"backbone.layers.15.mixer.D\", \"backbone.layers.15.mixer.in_proj.weight\", \"backbone.layers.15.mixer.conv1d.weight\", \"backbone.layers.15.mixer.conv1d.bias\", \"backbone.layers.15.mixer.out_proj.weight\", \"backbone.layers.15.input_layernorm.weight\", \"backbone.layers.15.post_attention_layernorm.weight\", \"backbone.layers.15.mlp.gate_proj.weight\", \"backbone.layers.15.mlp.up_proj.weight\", \"backbone.layers.15.mlp.down_proj.weight\", \"backbone.final_layernorm.weight\". \n\tUnexpected key(s) in state_dict: \"model.embed_tokens.weight\", \"model.layers.0.self_attn.q_proj.weight\", \"model.layers.0.self_attn.k_proj.weight\", \"model.layers.0.self_attn.v_proj.weight\", \"model.layers.0.self_attn.o_proj.weight\", \"model.layers.0.mlp.gate_proj.weight\", \"model.layers.0.mlp.up_proj.weight\", \"model.layers.0.mlp.down_proj.weight\", \"model.layers.0.input_layernorm.weight\", \"model.layers.0.post_attention_layernorm.weight\", \"model.layers.1.self_attn.q_proj.weight\", \"model.layers.1.self_attn.k_proj.weight\", \"model.layers.1.self_attn.v_proj.weight\", \"model.layers.1.self_attn.o_proj.weight\", \"model.layers.1.mlp.gate_proj.weight\", \"model.layers.1.mlp.up_proj.weight\", \"model.layers.1.mlp.down_proj.weight\", \"model.layers.1.input_layernorm.weight\", \"model.layers.1.post_attention_layernorm.weight\", \"model.layers.2.self_attn.q_proj.weight\", \"model.layers.2.self_attn.k_proj.weight\", \"model.layers.2.self_attn.v_proj.weight\", \"model.layers.2.self_attn.o_proj.weight\", \"model.layers.2.mlp.gate_proj.weight\", \"model.layers.2.mlp.up_proj.weight\", \"model.layers.2.mlp.down_proj.weight\", \"model.layers.2.input_layernorm.weight\", \"model.layers.2.post_attention_layernorm.weight\", \"model.layers.3.self_attn.q_proj.weight\", \"model.layers.3.self_attn.k_proj.weight\", \"model.layers.3.self_attn.v_proj.weight\", \"model.layers.3.self_attn.o_proj.weight\", \"model.layers.3.mlp.gate_proj.weight\", \"model.layers.3.mlp.up_proj.weight\", \"model.layers.3.mlp.down_proj.weight\", \"model.layers.3.input_layernorm.weight\", \"model.layers.3.post_attention_layernorm.weight\", \"model.layers.4.self_attn.q_proj.weight\", \"model.layers.4.self_attn.k_proj.weight\", \"model.layers.4.self_attn.v_proj.weight\", \"model.layers.4.self_attn.o_proj.weight\", \"model.layers.4.mlp.gate_proj.weight\", \"model.layers.4.mlp.up_proj.weight\", \"model.layers.4.mlp.down_proj.weight\", \"model.layers.4.input_layernorm.weight\", \"model.layers.4.post_attention_layernorm.weight\", \"model.layers.5.self_attn.q_proj.weight\", \"model.layers.5.self_attn.k_proj.weight\", \"model.layers.5.self_attn.v_proj.weight\", \"model.layers.5.self_attn.o_proj.weight\", \"model.layers.5.mlp.gate_proj.weight\", \"model.layers.5.mlp.up_proj.weight\", \"model.layers.5.mlp.down_proj.weight\", \"model.layers.5.input_layernorm.weight\", \"model.layers.5.post_attention_layernorm.weight\", \"model.layers.6.self_attn.q_proj.weight\", \"model.layers.6.self_attn.k_proj.weight\", \"model.layers.6.self_attn.v_proj.weight\", \"model.layers.6.self_attn.o_proj.weight\", \"model.layers.6.mlp.gate_proj.weight\", \"model.layers.6.mlp.up_proj.weight\", \"model.layers.6.mlp.down_proj.weight\", \"model.layers.6.input_layernorm.weight\", \"model.layers.6.post_attention_layernorm.weight\", \"model.layers.7.self_attn.q_proj.weight\", \"model.layers.7.self_attn.k_proj.weight\", \"model.layers.7.self_attn.v_proj.weight\", \"model.layers.7.self_attn.o_proj.weight\", \"model.layers.7.mlp.gate_proj.weight\", \"model.layers.7.mlp.up_proj.weight\", \"model.layers.7.mlp.down_proj.weight\", \"model.layers.7.input_layernorm.weight\", \"model.layers.7.post_attention_layernorm.weight\", \"model.layers.8.self_attn.q_proj.weight\", \"model.layers.8.self_attn.k_proj.weight\", \"model.layers.8.self_attn.v_proj.weight\", \"model.layers.8.self_attn.o_proj.weight\", \"model.layers.8.mlp.gate_proj.weight\", \"model.layers.8.mlp.up_proj.weight\", \"model.layers.8.mlp.down_proj.weight\", \"model.layers.8.input_layernorm.weight\", \"model.layers.8.post_attention_layernorm.weight\", \"model.layers.9.self_attn.q_proj.weight\", \"model.layers.9.self_attn.k_proj.weight\", \"model.layers.9.self_attn.v_proj.weight\", \"model.layers.9.self_attn.o_proj.weight\", \"model.layers.9.mlp.gate_proj.weight\", \"model.layers.9.mlp.up_proj.weight\", \"model.layers.9.mlp.down_proj.weight\", \"model.layers.9.input_layernorm.weight\", \"model.layers.9.post_attention_layernorm.weight\", \"model.layers.10.self_attn.q_proj.weight\", \"model.layers.10.self_attn.k_proj.weight\", \"model.layers.10.self_attn.v_proj.weight\", \"model.layers.10.self_attn.o_proj.weight\", \"model.layers.10.mlp.gate_proj.weight\", \"model.layers.10.mlp.up_proj.weight\", \"model.layers.10.mlp.down_proj.weight\", \"model.layers.10.input_layernorm.weight\", \"model.layers.10.post_attention_layernorm.weight\", \"model.layers.11.self_attn.q_proj.weight\", \"model.layers.11.self_attn.k_proj.weight\", \"model.layers.11.self_attn.v_proj.weight\", \"model.layers.11.self_attn.o_proj.weight\", \"model.layers.11.mlp.gate_proj.weight\", \"model.layers.11.mlp.up_proj.weight\", \"model.layers.11.mlp.down_proj.weight\", \"model.layers.11.input_layernorm.weight\", \"model.layers.11.post_attention_layernorm.weight\", \"model.layers.12.self_attn.q_proj.weight\", \"model.layers.12.self_attn.k_proj.weight\", \"model.layers.12.self_attn.v_proj.weight\", \"model.layers.12.self_attn.o_proj.weight\", \"model.layers.12.mlp.gate_proj.weight\", \"model.layers.12.mlp.up_proj.weight\", \"model.layers.12.mlp.down_proj.weight\", \"model.layers.12.input_layernorm.weight\", \"model.layers.12.post_attention_layernorm.weight\", \"model.layers.13.self_attn.q_proj.weight\", \"model.layers.13.self_attn.k_proj.weight\", \"model.layers.13.self_attn.v_proj.weight\", \"model.layers.13.self_attn.o_proj.weight\", \"model.layers.13.mlp.gate_proj.weight\", \"model.layers.13.mlp.up_proj.weight\", \"model.layers.13.mlp.down_proj.weight\", \"model.layers.13.input_layernorm.weight\", \"model.layers.13.post_attention_layernorm.weight\", \"model.layers.14.self_attn.q_proj.weight\", \"model.layers.14.self_attn.k_proj.weight\", \"model.layers.14.self_attn.v_proj.weight\", \"model.layers.14.self_attn.o_proj.weight\", \"model.layers.14.mlp.gate_proj.weight\", \"model.layers.14.mlp.up_proj.weight\", \"model.layers.14.mlp.down_proj.weight\", \"model.layers.14.input_layernorm.weight\", \"model.layers.14.post_attention_layernorm.weight\", \"model.layers.15.self_attn.q_proj.weight\", \"model.layers.15.self_attn.k_proj.weight\", \"model.layers.15.self_attn.v_proj.weight\", \"model.layers.15.self_attn.o_proj.weight\", \"model.layers.15.mlp.gate_proj.weight\", \"model.layers.15.mlp.up_proj.weight\", \"model.layers.15.mlp.down_proj.weight\", \"model.layers.15.input_layernorm.weight\", \"model.layers.15.post_attention_layernorm.weight\", \"model.norm.weight\". "
     ]
    }
   ],
   "source": [
    "llamba.load_state_dict(state_dict, strict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Llamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaConfig, LlamaForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    }
   ],
   "source": [
    "llama_config = LlamaConfig.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamba_config = LlambaConfig(**llama_config.to_dict(),\n",
    "                             d_model=llama_config.hidden_size)\n",
    "llamba = LlambaLMHeadModel(llamba_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    }
   ],
   "source": [
    "llama_model = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\", torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "state_dict = llama_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['backbone.embedding.weight', 'backbone.layers.0.mixer.z_bias', 'backbone.layers.0.mixer.D', 'backbone.layers.0.mixer.in_proj.weight', 'backbone.layers.0.mixer.conv1d.weight', 'backbone.layers.0.mixer.conv1d.bias', 'backbone.layers.0.mixer.out_proj.weight', 'backbone.layers.0.input_layernorm.weight', 'backbone.layers.0.post_attention_layernorm.weight', 'backbone.layers.0.mlp.gate_proj.weight', 'backbone.layers.0.mlp.up_proj.weight', 'backbone.layers.0.mlp.down_proj.weight', 'backbone.layers.1.mixer.z_bias', 'backbone.layers.1.mixer.D', 'backbone.layers.1.mixer.in_proj.weight', 'backbone.layers.1.mixer.conv1d.weight', 'backbone.layers.1.mixer.conv1d.bias', 'backbone.layers.1.mixer.out_proj.weight', 'backbone.layers.1.input_layernorm.weight', 'backbone.layers.1.post_attention_layernorm.weight', 'backbone.layers.1.mlp.gate_proj.weight', 'backbone.layers.1.mlp.up_proj.weight', 'backbone.layers.1.mlp.down_proj.weight', 'backbone.layers.2.mixer.z_bias', 'backbone.layers.2.mixer.D', 'backbone.layers.2.mixer.in_proj.weight', 'backbone.layers.2.mixer.conv1d.weight', 'backbone.layers.2.mixer.conv1d.bias', 'backbone.layers.2.mixer.out_proj.weight', 'backbone.layers.2.input_layernorm.weight', 'backbone.layers.2.post_attention_layernorm.weight', 'backbone.layers.2.mlp.gate_proj.weight', 'backbone.layers.2.mlp.up_proj.weight', 'backbone.layers.2.mlp.down_proj.weight', 'backbone.layers.3.mixer.z_bias', 'backbone.layers.3.mixer.D', 'backbone.layers.3.mixer.in_proj.weight', 'backbone.layers.3.mixer.conv1d.weight', 'backbone.layers.3.mixer.conv1d.bias', 'backbone.layers.3.mixer.out_proj.weight', 'backbone.layers.3.input_layernorm.weight', 'backbone.layers.3.post_attention_layernorm.weight', 'backbone.layers.3.mlp.gate_proj.weight', 'backbone.layers.3.mlp.up_proj.weight', 'backbone.layers.3.mlp.down_proj.weight', 'backbone.layers.4.mixer.z_bias', 'backbone.layers.4.mixer.D', 'backbone.layers.4.mixer.in_proj.weight', 'backbone.layers.4.mixer.conv1d.weight', 'backbone.layers.4.mixer.conv1d.bias', 'backbone.layers.4.mixer.out_proj.weight', 'backbone.layers.4.input_layernorm.weight', 'backbone.layers.4.post_attention_layernorm.weight', 'backbone.layers.4.mlp.gate_proj.weight', 'backbone.layers.4.mlp.up_proj.weight', 'backbone.layers.4.mlp.down_proj.weight', 'backbone.layers.5.mixer.z_bias', 'backbone.layers.5.mixer.D', 'backbone.layers.5.mixer.in_proj.weight', 'backbone.layers.5.mixer.conv1d.weight', 'backbone.layers.5.mixer.conv1d.bias', 'backbone.layers.5.mixer.out_proj.weight', 'backbone.layers.5.input_layernorm.weight', 'backbone.layers.5.post_attention_layernorm.weight', 'backbone.layers.5.mlp.gate_proj.weight', 'backbone.layers.5.mlp.up_proj.weight', 'backbone.layers.5.mlp.down_proj.weight', 'backbone.layers.6.mixer.z_bias', 'backbone.layers.6.mixer.D', 'backbone.layers.6.mixer.in_proj.weight', 'backbone.layers.6.mixer.conv1d.weight', 'backbone.layers.6.mixer.conv1d.bias', 'backbone.layers.6.mixer.out_proj.weight', 'backbone.layers.6.input_layernorm.weight', 'backbone.layers.6.post_attention_layernorm.weight', 'backbone.layers.6.mlp.gate_proj.weight', 'backbone.layers.6.mlp.up_proj.weight', 'backbone.layers.6.mlp.down_proj.weight', 'backbone.layers.7.mixer.z_bias', 'backbone.layers.7.mixer.D', 'backbone.layers.7.mixer.in_proj.weight', 'backbone.layers.7.mixer.conv1d.weight', 'backbone.layers.7.mixer.conv1d.bias', 'backbone.layers.7.mixer.out_proj.weight', 'backbone.layers.7.input_layernorm.weight', 'backbone.layers.7.post_attention_layernorm.weight', 'backbone.layers.7.mlp.gate_proj.weight', 'backbone.layers.7.mlp.up_proj.weight', 'backbone.layers.7.mlp.down_proj.weight', 'backbone.layers.8.mixer.z_bias', 'backbone.layers.8.mixer.D', 'backbone.layers.8.mixer.in_proj.weight', 'backbone.layers.8.mixer.conv1d.weight', 'backbone.layers.8.mixer.conv1d.bias', 'backbone.layers.8.mixer.out_proj.weight', 'backbone.layers.8.input_layernorm.weight', 'backbone.layers.8.post_attention_layernorm.weight', 'backbone.layers.8.mlp.gate_proj.weight', 'backbone.layers.8.mlp.up_proj.weight', 'backbone.layers.8.mlp.down_proj.weight', 'backbone.layers.9.mixer.z_bias', 'backbone.layers.9.mixer.D', 'backbone.layers.9.mixer.in_proj.weight', 'backbone.layers.9.mixer.conv1d.weight', 'backbone.layers.9.mixer.conv1d.bias', 'backbone.layers.9.mixer.out_proj.weight', 'backbone.layers.9.input_layernorm.weight', 'backbone.layers.9.post_attention_layernorm.weight', 'backbone.layers.9.mlp.gate_proj.weight', 'backbone.layers.9.mlp.up_proj.weight', 'backbone.layers.9.mlp.down_proj.weight', 'backbone.layers.10.mixer.z_bias', 'backbone.layers.10.mixer.D', 'backbone.layers.10.mixer.in_proj.weight', 'backbone.layers.10.mixer.conv1d.weight', 'backbone.layers.10.mixer.conv1d.bias', 'backbone.layers.10.mixer.out_proj.weight', 'backbone.layers.10.input_layernorm.weight', 'backbone.layers.10.post_attention_layernorm.weight', 'backbone.layers.10.mlp.gate_proj.weight', 'backbone.layers.10.mlp.up_proj.weight', 'backbone.layers.10.mlp.down_proj.weight', 'backbone.layers.11.mixer.z_bias', 'backbone.layers.11.mixer.D', 'backbone.layers.11.mixer.in_proj.weight', 'backbone.layers.11.mixer.conv1d.weight', 'backbone.layers.11.mixer.conv1d.bias', 'backbone.layers.11.mixer.out_proj.weight', 'backbone.layers.11.input_layernorm.weight', 'backbone.layers.11.post_attention_layernorm.weight', 'backbone.layers.11.mlp.gate_proj.weight', 'backbone.layers.11.mlp.up_proj.weight', 'backbone.layers.11.mlp.down_proj.weight', 'backbone.layers.12.mixer.z_bias', 'backbone.layers.12.mixer.D', 'backbone.layers.12.mixer.in_proj.weight', 'backbone.layers.12.mixer.conv1d.weight', 'backbone.layers.12.mixer.conv1d.bias', 'backbone.layers.12.mixer.out_proj.weight', 'backbone.layers.12.input_layernorm.weight', 'backbone.layers.12.post_attention_layernorm.weight', 'backbone.layers.12.mlp.gate_proj.weight', 'backbone.layers.12.mlp.up_proj.weight', 'backbone.layers.12.mlp.down_proj.weight', 'backbone.layers.13.mixer.z_bias', 'backbone.layers.13.mixer.D', 'backbone.layers.13.mixer.in_proj.weight', 'backbone.layers.13.mixer.conv1d.weight', 'backbone.layers.13.mixer.conv1d.bias', 'backbone.layers.13.mixer.out_proj.weight', 'backbone.layers.13.input_layernorm.weight', 'backbone.layers.13.post_attention_layernorm.weight', 'backbone.layers.13.mlp.gate_proj.weight', 'backbone.layers.13.mlp.up_proj.weight', 'backbone.layers.13.mlp.down_proj.weight', 'backbone.layers.14.mixer.z_bias', 'backbone.layers.14.mixer.D', 'backbone.layers.14.mixer.in_proj.weight', 'backbone.layers.14.mixer.conv1d.weight', 'backbone.layers.14.mixer.conv1d.bias', 'backbone.layers.14.mixer.out_proj.weight', 'backbone.layers.14.input_layernorm.weight', 'backbone.layers.14.post_attention_layernorm.weight', 'backbone.layers.14.mlp.gate_proj.weight', 'backbone.layers.14.mlp.up_proj.weight', 'backbone.layers.14.mlp.down_proj.weight', 'backbone.layers.15.mixer.z_bias', 'backbone.layers.15.mixer.D', 'backbone.layers.15.mixer.in_proj.weight', 'backbone.layers.15.mixer.conv1d.weight', 'backbone.layers.15.mixer.conv1d.bias', 'backbone.layers.15.mixer.out_proj.weight', 'backbone.layers.15.input_layernorm.weight', 'backbone.layers.15.post_attention_layernorm.weight', 'backbone.layers.15.mlp.gate_proj.weight', 'backbone.layers.15.mlp.up_proj.weight', 'backbone.layers.15.mlp.down_proj.weight', 'backbone.layers.16.mixer.z_bias', 'backbone.layers.16.mixer.D', 'backbone.layers.16.mixer.in_proj.weight', 'backbone.layers.16.mixer.conv1d.weight', 'backbone.layers.16.mixer.conv1d.bias', 'backbone.layers.16.mixer.out_proj.weight', 'backbone.layers.16.input_layernorm.weight', 'backbone.layers.16.post_attention_layernorm.weight', 'backbone.layers.16.mlp.gate_proj.weight', 'backbone.layers.16.mlp.up_proj.weight', 'backbone.layers.16.mlp.down_proj.weight', 'backbone.layers.17.mixer.z_bias', 'backbone.layers.17.mixer.D', 'backbone.layers.17.mixer.in_proj.weight', 'backbone.layers.17.mixer.conv1d.weight', 'backbone.layers.17.mixer.conv1d.bias', 'backbone.layers.17.mixer.out_proj.weight', 'backbone.layers.17.input_layernorm.weight', 'backbone.layers.17.post_attention_layernorm.weight', 'backbone.layers.17.mlp.gate_proj.weight', 'backbone.layers.17.mlp.up_proj.weight', 'backbone.layers.17.mlp.down_proj.weight', 'backbone.layers.18.mixer.z_bias', 'backbone.layers.18.mixer.D', 'backbone.layers.18.mixer.in_proj.weight', 'backbone.layers.18.mixer.conv1d.weight', 'backbone.layers.18.mixer.conv1d.bias', 'backbone.layers.18.mixer.out_proj.weight', 'backbone.layers.18.input_layernorm.weight', 'backbone.layers.18.post_attention_layernorm.weight', 'backbone.layers.18.mlp.gate_proj.weight', 'backbone.layers.18.mlp.up_proj.weight', 'backbone.layers.18.mlp.down_proj.weight', 'backbone.layers.19.mixer.z_bias', 'backbone.layers.19.mixer.D', 'backbone.layers.19.mixer.in_proj.weight', 'backbone.layers.19.mixer.conv1d.weight', 'backbone.layers.19.mixer.conv1d.bias', 'backbone.layers.19.mixer.out_proj.weight', 'backbone.layers.19.input_layernorm.weight', 'backbone.layers.19.post_attention_layernorm.weight', 'backbone.layers.19.mlp.gate_proj.weight', 'backbone.layers.19.mlp.up_proj.weight', 'backbone.layers.19.mlp.down_proj.weight', 'backbone.layers.20.mixer.z_bias', 'backbone.layers.20.mixer.D', 'backbone.layers.20.mixer.in_proj.weight', 'backbone.layers.20.mixer.conv1d.weight', 'backbone.layers.20.mixer.conv1d.bias', 'backbone.layers.20.mixer.out_proj.weight', 'backbone.layers.20.input_layernorm.weight', 'backbone.layers.20.post_attention_layernorm.weight', 'backbone.layers.20.mlp.gate_proj.weight', 'backbone.layers.20.mlp.up_proj.weight', 'backbone.layers.20.mlp.down_proj.weight', 'backbone.layers.21.mixer.z_bias', 'backbone.layers.21.mixer.D', 'backbone.layers.21.mixer.in_proj.weight', 'backbone.layers.21.mixer.conv1d.weight', 'backbone.layers.21.mixer.conv1d.bias', 'backbone.layers.21.mixer.out_proj.weight', 'backbone.layers.21.input_layernorm.weight', 'backbone.layers.21.post_attention_layernorm.weight', 'backbone.layers.21.mlp.gate_proj.weight', 'backbone.layers.21.mlp.up_proj.weight', 'backbone.layers.21.mlp.down_proj.weight', 'backbone.layers.22.mixer.z_bias', 'backbone.layers.22.mixer.D', 'backbone.layers.22.mixer.in_proj.weight', 'backbone.layers.22.mixer.conv1d.weight', 'backbone.layers.22.mixer.conv1d.bias', 'backbone.layers.22.mixer.out_proj.weight', 'backbone.layers.22.input_layernorm.weight', 'backbone.layers.22.post_attention_layernorm.weight', 'backbone.layers.22.mlp.gate_proj.weight', 'backbone.layers.22.mlp.up_proj.weight', 'backbone.layers.22.mlp.down_proj.weight', 'backbone.layers.23.mixer.z_bias', 'backbone.layers.23.mixer.D', 'backbone.layers.23.mixer.in_proj.weight', 'backbone.layers.23.mixer.conv1d.weight', 'backbone.layers.23.mixer.conv1d.bias', 'backbone.layers.23.mixer.out_proj.weight', 'backbone.layers.23.input_layernorm.weight', 'backbone.layers.23.post_attention_layernorm.weight', 'backbone.layers.23.mlp.gate_proj.weight', 'backbone.layers.23.mlp.up_proj.weight', 'backbone.layers.23.mlp.down_proj.weight', 'backbone.layers.24.mixer.z_bias', 'backbone.layers.24.mixer.D', 'backbone.layers.24.mixer.in_proj.weight', 'backbone.layers.24.mixer.conv1d.weight', 'backbone.layers.24.mixer.conv1d.bias', 'backbone.layers.24.mixer.out_proj.weight', 'backbone.layers.24.input_layernorm.weight', 'backbone.layers.24.post_attention_layernorm.weight', 'backbone.layers.24.mlp.gate_proj.weight', 'backbone.layers.24.mlp.up_proj.weight', 'backbone.layers.24.mlp.down_proj.weight', 'backbone.layers.25.mixer.z_bias', 'backbone.layers.25.mixer.D', 'backbone.layers.25.mixer.in_proj.weight', 'backbone.layers.25.mixer.conv1d.weight', 'backbone.layers.25.mixer.conv1d.bias', 'backbone.layers.25.mixer.out_proj.weight', 'backbone.layers.25.input_layernorm.weight', 'backbone.layers.25.post_attention_layernorm.weight', 'backbone.layers.25.mlp.gate_proj.weight', 'backbone.layers.25.mlp.up_proj.weight', 'backbone.layers.25.mlp.down_proj.weight', 'backbone.layers.26.mixer.z_bias', 'backbone.layers.26.mixer.D', 'backbone.layers.26.mixer.in_proj.weight', 'backbone.layers.26.mixer.conv1d.weight', 'backbone.layers.26.mixer.conv1d.bias', 'backbone.layers.26.mixer.out_proj.weight', 'backbone.layers.26.input_layernorm.weight', 'backbone.layers.26.post_attention_layernorm.weight', 'backbone.layers.26.mlp.gate_proj.weight', 'backbone.layers.26.mlp.up_proj.weight', 'backbone.layers.26.mlp.down_proj.weight', 'backbone.layers.27.mixer.z_bias', 'backbone.layers.27.mixer.D', 'backbone.layers.27.mixer.in_proj.weight', 'backbone.layers.27.mixer.conv1d.weight', 'backbone.layers.27.mixer.conv1d.bias', 'backbone.layers.27.mixer.out_proj.weight', 'backbone.layers.27.input_layernorm.weight', 'backbone.layers.27.post_attention_layernorm.weight', 'backbone.layers.27.mlp.gate_proj.weight', 'backbone.layers.27.mlp.up_proj.weight', 'backbone.layers.27.mlp.down_proj.weight', 'backbone.layers.28.mixer.z_bias', 'backbone.layers.28.mixer.D', 'backbone.layers.28.mixer.in_proj.weight', 'backbone.layers.28.mixer.conv1d.weight', 'backbone.layers.28.mixer.conv1d.bias', 'backbone.layers.28.mixer.out_proj.weight', 'backbone.layers.28.input_layernorm.weight', 'backbone.layers.28.post_attention_layernorm.weight', 'backbone.layers.28.mlp.gate_proj.weight', 'backbone.layers.28.mlp.up_proj.weight', 'backbone.layers.28.mlp.down_proj.weight', 'backbone.layers.29.mixer.z_bias', 'backbone.layers.29.mixer.D', 'backbone.layers.29.mixer.in_proj.weight', 'backbone.layers.29.mixer.conv1d.weight', 'backbone.layers.29.mixer.conv1d.bias', 'backbone.layers.29.mixer.out_proj.weight', 'backbone.layers.29.input_layernorm.weight', 'backbone.layers.29.post_attention_layernorm.weight', 'backbone.layers.29.mlp.gate_proj.weight', 'backbone.layers.29.mlp.up_proj.weight', 'backbone.layers.29.mlp.down_proj.weight', 'backbone.layers.30.mixer.z_bias', 'backbone.layers.30.mixer.D', 'backbone.layers.30.mixer.in_proj.weight', 'backbone.layers.30.mixer.conv1d.weight', 'backbone.layers.30.mixer.conv1d.bias', 'backbone.layers.30.mixer.out_proj.weight', 'backbone.layers.30.input_layernorm.weight', 'backbone.layers.30.post_attention_layernorm.weight', 'backbone.layers.30.mlp.gate_proj.weight', 'backbone.layers.30.mlp.up_proj.weight', 'backbone.layers.30.mlp.down_proj.weight', 'backbone.layers.31.mixer.z_bias', 'backbone.layers.31.mixer.D', 'backbone.layers.31.mixer.in_proj.weight', 'backbone.layers.31.mixer.conv1d.weight', 'backbone.layers.31.mixer.conv1d.bias', 'backbone.layers.31.mixer.out_proj.weight', 'backbone.layers.31.input_layernorm.weight', 'backbone.layers.31.post_attention_layernorm.weight', 'backbone.layers.31.mlp.gate_proj.weight', 'backbone.layers.31.mlp.up_proj.weight', 'backbone.layers.31.mlp.down_proj.weight', 'backbone.final_layernorm.weight'], unexpected_keys=['model.embed_tokens.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.mlp.down_proj.weight', 'model.layers.0.input_layernorm.weight', 'model.layers.0.post_attention_layernorm.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.input_layernorm.weight', 'model.layers.1.post_attention_layernorm.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.input_layernorm.weight', 'model.layers.2.post_attention_layernorm.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.input_layernorm.weight', 'model.layers.3.post_attention_layernorm.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.input_layernorm.weight', 'model.layers.4.post_attention_layernorm.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.input_layernorm.weight', 'model.layers.5.post_attention_layernorm.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.input_layernorm.weight', 'model.layers.6.post_attention_layernorm.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.input_layernorm.weight', 'model.layers.7.post_attention_layernorm.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.input_layernorm.weight', 'model.layers.8.post_attention_layernorm.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.input_layernorm.weight', 'model.layers.9.post_attention_layernorm.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.input_layernorm.weight', 'model.layers.10.post_attention_layernorm.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.input_layernorm.weight', 'model.layers.11.post_attention_layernorm.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.input_layernorm.weight', 'model.layers.12.post_attention_layernorm.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.input_layernorm.weight', 'model.layers.13.post_attention_layernorm.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.input_layernorm.weight', 'model.layers.14.post_attention_layernorm.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.input_layernorm.weight', 'model.layers.15.post_attention_layernorm.weight', 'model.norm.weight'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "llamba.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llamba.save_pretrained(\"/mnt/checkpoints/ssm/llamba1b_from_llama32instruct_ssminit_rand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hymba2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
