{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toolkit/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "# from transformers import MistralForCausalLM\n",
    "# from fast_llm.models.ssm.external.apriel_15b_hybrid.configuration_ssm_hybrid_apriel15b import AprielSSMHybridConfig\n",
    "# from fast_llm.models.ssm.external.apriel_15b_hybrid.modeling_ssm_hybrid_apriel15b import AprielSSMHybridForCausalLM\n",
    "# autoreload changes to the code\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"/mnt/checkpoints/fast_llm_exp/slam_ssm_distill/15bch-ifrhyb20l32h-bs768-lr0.0003-lrs0-0-0-0-sl4096_ti1000_lm2/export/apriel_ssm_thinker_hybrid/1000\"\n",
    "# AutoConfig.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"/mnt/checkpoints/fast_llm_exp/slam_ssm_distill/15bch-ifrhyb20l32h-bs768-lr0.0003-lrs0-0-0-0-sl4096_ti1000_lm2/export/apriel_ssm_thinker_hybrid/1000\"\n",
    "# m = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_path, trust_remote_code=True,\n",
    "#     config=AutoConfig.from_pretrained(model_path, trust_remote_code=True),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slam 15B upcycled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Lead the weights of https://huggingface.co/ServiceNow-AI/Slam-15B-Upcycled/ into Thiked modeling, it shoudl work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/toolkit/dev/fml-ops/__oo_playground\")\n",
    "from results_analysis.results_loader import ResultsLoader\n",
    "layer_importance_path = \"/mnt/evaluations/training_evaluation/model_runs/lm_eval_runner/apriel_ssm_importance/\"\n",
    "results_loader = ResultsLoader(layer_importance_path)\n",
    "\n",
    "results_loader.deserialize_results()\n",
    "results_df = results_loader.to_df()\n",
    "results_df[\"layer_index\"] = results_df.apply(lambda row: int(row[\"model_name_sanitized\"].split(\"_\")[-1] if \"layers_\" in row[\"model_name_sanitized\"] else -1), axis=1)\n",
    "results_df = results_df[results_df[\"metric\"] == \"acc_norm\"]\n",
    "columns_to_keep = [\"layer_index\", \"metric_value\"]\n",
    "results_df = results_df[columns_to_keep]\n",
    "layer_importance = results_df.groupby(\"layer_index\").mean()\n",
    "layer_importance = layer_importance.sort_values(by=\"metric_value\", ascending=False).reset_index()\n",
    "layer_importance = layer_importance[layer_importance[\"layer_index\"]!= -1]\n",
    "layer_importance = list(layer_importance[\"layer_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22,\n",
       " 25,\n",
       " 20,\n",
       " 31,\n",
       " 29,\n",
       " 46,\n",
       " 23,\n",
       " 26,\n",
       " 33,\n",
       " 24,\n",
       " 47,\n",
       " 27,\n",
       " 21,\n",
       " 41,\n",
       " 17,\n",
       " 18,\n",
       " 34,\n",
       " 42,\n",
       " 44,\n",
       " 30,\n",
       " 16,\n",
       " 8,\n",
       " 43,\n",
       " 35,\n",
       " 19,\n",
       " 38,\n",
       " 15,\n",
       " 28,\n",
       " 32,\n",
       " 45,\n",
       " 37,\n",
       " 40,\n",
       " 7,\n",
       " 36,\n",
       " 13,\n",
       " 10,\n",
       " 5,\n",
       " 39,\n",
       " 6,\n",
       " 14,\n",
       " 4,\n",
       " 12,\n",
       " 9,\n",
       " 48,\n",
       " 1,\n",
       " 3,\n",
       " 11,\n",
       " 49,\n",
       " 0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_thinker = \"/mnt/checkpoints/upstream/Apriel-Nemotron-15b-Thinker\"\n",
    "n_ssm = 25\n",
    "\n",
    "config_thinker = AutoConfig.from_pretrained(path_thinker)\n",
    "hybrid_block_layout = [\"t\"] * config_thinker.num_hidden_layers\n",
    "\n",
    "for i in range(n_ssm):\n",
    "    hybrid_block_layout[layer_importance[i]] = \"m2d\"\n",
    "\n",
    "config_hybrid = AprielSSMHybridConfig(\n",
    "    **config_thinker.to_dict(),\n",
    "    hybrid_block_layout=hybrid_block_layout,\n",
    "    ssm_cfg = {\n",
    "            \"d_state\": 64,\n",
    "            \"n_v_heads\": 32,\n",
    "            \"n_qk_heads\": 32,\n",
    "            \"expand\": 1,\n",
    "            \"chunk_size\": 128,\n",
    "            \"activation\": \"identity\",\n",
    "            \"bias\": False,\n",
    "            \"d_conv\": 4,\n",
    "            \"d_inner\": 32 * 128\n",
    "        }\n",
    ")\n",
    "model_hybrid = AprielSSMHybridForCausalLM(config_hybrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'm2d',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 't',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 't',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 't',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 't',\n",
       " 't']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_block_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llama to instantiate a model of type mistral. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.52it/s]\n"
     ]
    }
   ],
   "source": [
    "path_base = \"/mnt/checkpoints/upstream/Slam-15B-Upcycled\"\n",
    "# path_base = \"/mnt/checkpoints/upstream/Slam-15B-Upcycled-mistral\"\n",
    "model_base = MistralForCausalLM.from_pretrained(path_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['model.layers.8.mixer.z_bias', 'model.layers.8.mixer.D', 'model.layers.8.mixer.in_proj.weight', 'model.layers.8.mixer.conv1d.weight', 'model.layers.8.mixer.conv1d.bias', 'model.layers.8.mixer.out_proj.weight', 'model.layers.16.mixer.z_bias', 'model.layers.16.mixer.D', 'model.layers.16.mixer.in_proj.weight', 'model.layers.16.mixer.conv1d.weight', 'model.layers.16.mixer.conv1d.bias', 'model.layers.16.mixer.out_proj.weight', 'model.layers.17.mixer.z_bias', 'model.layers.17.mixer.D', 'model.layers.17.mixer.in_proj.weight', 'model.layers.17.mixer.conv1d.weight', 'model.layers.17.mixer.conv1d.bias', 'model.layers.17.mixer.out_proj.weight', 'model.layers.18.mixer.z_bias', 'model.layers.18.mixer.D', 'model.layers.18.mixer.in_proj.weight', 'model.layers.18.mixer.conv1d.weight', 'model.layers.18.mixer.conv1d.bias', 'model.layers.18.mixer.out_proj.weight', 'model.layers.19.mixer.z_bias', 'model.layers.19.mixer.D', 'model.layers.19.mixer.in_proj.weight', 'model.layers.19.mixer.conv1d.weight', 'model.layers.19.mixer.conv1d.bias', 'model.layers.19.mixer.out_proj.weight', 'model.layers.20.mixer.z_bias', 'model.layers.20.mixer.D', 'model.layers.20.mixer.in_proj.weight', 'model.layers.20.mixer.conv1d.weight', 'model.layers.20.mixer.conv1d.bias', 'model.layers.20.mixer.out_proj.weight', 'model.layers.21.mixer.z_bias', 'model.layers.21.mixer.D', 'model.layers.21.mixer.in_proj.weight', 'model.layers.21.mixer.conv1d.weight', 'model.layers.21.mixer.conv1d.bias', 'model.layers.21.mixer.out_proj.weight', 'model.layers.22.mixer.z_bias', 'model.layers.22.mixer.D', 'model.layers.22.mixer.in_proj.weight', 'model.layers.22.mixer.conv1d.weight', 'model.layers.22.mixer.conv1d.bias', 'model.layers.22.mixer.out_proj.weight', 'model.layers.23.mixer.z_bias', 'model.layers.23.mixer.D', 'model.layers.23.mixer.in_proj.weight', 'model.layers.23.mixer.conv1d.weight', 'model.layers.23.mixer.conv1d.bias', 'model.layers.23.mixer.out_proj.weight', 'model.layers.24.mixer.z_bias', 'model.layers.24.mixer.D', 'model.layers.24.mixer.in_proj.weight', 'model.layers.24.mixer.conv1d.weight', 'model.layers.24.mixer.conv1d.bias', 'model.layers.24.mixer.out_proj.weight', 'model.layers.25.mixer.z_bias', 'model.layers.25.mixer.D', 'model.layers.25.mixer.in_proj.weight', 'model.layers.25.mixer.conv1d.weight', 'model.layers.25.mixer.conv1d.bias', 'model.layers.25.mixer.out_proj.weight', 'model.layers.26.mixer.z_bias', 'model.layers.26.mixer.D', 'model.layers.26.mixer.in_proj.weight', 'model.layers.26.mixer.conv1d.weight', 'model.layers.26.mixer.conv1d.bias', 'model.layers.26.mixer.out_proj.weight', 'model.layers.27.mixer.z_bias', 'model.layers.27.mixer.D', 'model.layers.27.mixer.in_proj.weight', 'model.layers.27.mixer.conv1d.weight', 'model.layers.27.mixer.conv1d.bias', 'model.layers.27.mixer.out_proj.weight', 'model.layers.29.mixer.z_bias', 'model.layers.29.mixer.D', 'model.layers.29.mixer.in_proj.weight', 'model.layers.29.mixer.conv1d.weight', 'model.layers.29.mixer.conv1d.bias', 'model.layers.29.mixer.out_proj.weight', 'model.layers.30.mixer.z_bias', 'model.layers.30.mixer.D', 'model.layers.30.mixer.in_proj.weight', 'model.layers.30.mixer.conv1d.weight', 'model.layers.30.mixer.conv1d.bias', 'model.layers.30.mixer.out_proj.weight', 'model.layers.31.mixer.z_bias', 'model.layers.31.mixer.D', 'model.layers.31.mixer.in_proj.weight', 'model.layers.31.mixer.conv1d.weight', 'model.layers.31.mixer.conv1d.bias', 'model.layers.31.mixer.out_proj.weight', 'model.layers.33.mixer.z_bias', 'model.layers.33.mixer.D', 'model.layers.33.mixer.in_proj.weight', 'model.layers.33.mixer.conv1d.weight', 'model.layers.33.mixer.conv1d.bias', 'model.layers.33.mixer.out_proj.weight', 'model.layers.34.mixer.z_bias', 'model.layers.34.mixer.D', 'model.layers.34.mixer.in_proj.weight', 'model.layers.34.mixer.conv1d.weight', 'model.layers.34.mixer.conv1d.bias', 'model.layers.34.mixer.out_proj.weight', 'model.layers.35.mixer.z_bias', 'model.layers.35.mixer.D', 'model.layers.35.mixer.in_proj.weight', 'model.layers.35.mixer.conv1d.weight', 'model.layers.35.mixer.conv1d.bias', 'model.layers.35.mixer.out_proj.weight', 'model.layers.41.mixer.z_bias', 'model.layers.41.mixer.D', 'model.layers.41.mixer.in_proj.weight', 'model.layers.41.mixer.conv1d.weight', 'model.layers.41.mixer.conv1d.bias', 'model.layers.41.mixer.out_proj.weight', 'model.layers.42.mixer.z_bias', 'model.layers.42.mixer.D', 'model.layers.42.mixer.in_proj.weight', 'model.layers.42.mixer.conv1d.weight', 'model.layers.42.mixer.conv1d.bias', 'model.layers.42.mixer.out_proj.weight', 'model.layers.43.mixer.z_bias', 'model.layers.43.mixer.D', 'model.layers.43.mixer.in_proj.weight', 'model.layers.43.mixer.conv1d.weight', 'model.layers.43.mixer.conv1d.bias', 'model.layers.43.mixer.out_proj.weight', 'model.layers.44.mixer.z_bias', 'model.layers.44.mixer.D', 'model.layers.44.mixer.in_proj.weight', 'model.layers.44.mixer.conv1d.weight', 'model.layers.44.mixer.conv1d.bias', 'model.layers.44.mixer.out_proj.weight', 'model.layers.46.mixer.z_bias', 'model.layers.46.mixer.D', 'model.layers.46.mixer.in_proj.weight', 'model.layers.46.mixer.conv1d.weight', 'model.layers.46.mixer.conv1d.bias', 'model.layers.46.mixer.out_proj.weight', 'model.layers.47.mixer.z_bias', 'model.layers.47.mixer.D', 'model.layers.47.mixer.in_proj.weight', 'model.layers.47.mixer.conv1d.weight', 'model.layers.47.mixer.conv1d.bias', 'model.layers.47.mixer.out_proj.weight'], unexpected_keys=['model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.33.self_attn.q_proj.weight', 'model.layers.33.self_attn.k_proj.weight', 'model.layers.33.self_attn.v_proj.weight', 'model.layers.33.self_attn.o_proj.weight', 'model.layers.34.self_attn.q_proj.weight', 'model.layers.34.self_attn.k_proj.weight', 'model.layers.34.self_attn.v_proj.weight', 'model.layers.34.self_attn.o_proj.weight', 'model.layers.35.self_attn.q_proj.weight', 'model.layers.35.self_attn.k_proj.weight', 'model.layers.35.self_attn.v_proj.weight', 'model.layers.35.self_attn.o_proj.weight', 'model.layers.41.self_attn.q_proj.weight', 'model.layers.41.self_attn.k_proj.weight', 'model.layers.41.self_attn.v_proj.weight', 'model.layers.41.self_attn.o_proj.weight', 'model.layers.42.self_attn.q_proj.weight', 'model.layers.42.self_attn.k_proj.weight', 'model.layers.42.self_attn.v_proj.weight', 'model.layers.42.self_attn.o_proj.weight', 'model.layers.43.self_attn.q_proj.weight', 'model.layers.43.self_attn.k_proj.weight', 'model.layers.43.self_attn.v_proj.weight', 'model.layers.43.self_attn.o_proj.weight', 'model.layers.44.self_attn.q_proj.weight', 'model.layers.44.self_attn.k_proj.weight', 'model.layers.44.self_attn.v_proj.weight', 'model.layers.44.self_attn.o_proj.weight', 'model.layers.46.self_attn.q_proj.weight', 'model.layers.46.self_attn.k_proj.weight', 'model.layers.46.self_attn.v_proj.weight', 'model.layers.46.self_attn.o_proj.weight', 'model.layers.47.self_attn.q_proj.weight', 'model.layers.47.self_attn.k_proj.weight', 'model.layers.47.self_attn.v_proj.weight', 'model.layers.47.self_attn.o_proj.weight'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hybrid.load_state_dict(model_base.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid.save_pretrained(\"/mnt/checkpoints/ssm/apriel_ssm_base15b_hybrid_25ssm_leastimportant_32h_init_rand\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinker 15B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toolkit/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "import click\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from transformers import MistralForCausalLM\n",
    "\n",
    "from fast_llm.models.ssm.external.apriel_15b_hybrid.configuration_ssm_hybrid_apriel15b import AprielSSMHybridConfig\n",
    "from fast_llm.models.ssm.external.apriel_15b_hybrid.modeling_ssm_hybrid_apriel15b import AprielSSMHybridForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repalce specific layer from MOHAWK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:28<00:00,  4.02s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 14/14 [00:00<00:00, 232.07it/s]\n"
     ]
    }
   ],
   "source": [
    "l3checkpoint = \"/mnt/checkpoints/ssm/apriel_ssm_thinker15b_hybrid_25ssm_leastimportant_32h_init_rand\" #/mnt/checkpoints/ssm/iterative_hybrids_only_new_layer_train/apriel_ssm_thinker15b_hybrid_3ssm_leastimportant_32h_init_rand\"\n",
    "model_l3 = AprielSSMHybridForCausalLM.from_pretrained(l3checkpoint, device_map=\"cpu\")\n",
    "mohawk_checkpoint = \"/mnt/checkpoints_fml/ssm/final_stitched_model_L0-49_resaved\"\n",
    "model_mohawk = AprielSSMHybridForCausalLM.from_pretrained(mohawk_checkpoint, device_map=\"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'm2d',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 't',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 't',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 't',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 't',\n",
       " 't']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_l3.config.hybrid_block_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model.layers.0.mixer.z_bias', 'model.layers.0.mixer.D', 'model.layers.0.mixer.in_proj.weight', 'model.layers.0.mixer.conv1d.weight', 'model.layers.0.mixer.conv1d.bias', 'model.layers.0.mixer.out_proj.weight', 'model.layers.1.mixer.z_bias', 'model.layers.1.mixer.D', 'model.layers.1.mixer.in_proj.weight', 'model.layers.1.mixer.conv1d.weight', 'model.layers.1.mixer.conv1d.bias', 'model.layers.1.mixer.out_proj.weight', 'model.layers.2.mixer.z_bias', 'model.layers.2.mixer.D', 'model.layers.2.mixer.in_proj.weight', 'model.layers.2.mixer.conv1d.weight', 'model.layers.2.mixer.conv1d.bias', 'model.layers.2.mixer.out_proj.weight', 'model.layers.3.mixer.z_bias', 'model.layers.3.mixer.D', 'model.layers.3.mixer.in_proj.weight', 'model.layers.3.mixer.conv1d.weight', 'model.layers.3.mixer.conv1d.bias', 'model.layers.3.mixer.out_proj.weight', 'model.layers.4.mixer.z_bias', 'model.layers.4.mixer.D', 'model.layers.4.mixer.in_proj.weight', 'model.layers.4.mixer.conv1d.weight', 'model.layers.4.mixer.conv1d.bias', 'model.layers.4.mixer.out_proj.weight', 'model.layers.5.mixer.z_bias', 'model.layers.5.mixer.D', 'model.layers.5.mixer.in_proj.weight', 'model.layers.5.mixer.conv1d.weight', 'model.layers.5.mixer.conv1d.bias', 'model.layers.5.mixer.out_proj.weight', 'model.layers.6.mixer.z_bias', 'model.layers.6.mixer.D', 'model.layers.6.mixer.in_proj.weight', 'model.layers.6.mixer.conv1d.weight', 'model.layers.6.mixer.conv1d.bias', 'model.layers.6.mixer.out_proj.weight', 'model.layers.7.mixer.z_bias', 'model.layers.7.mixer.D', 'model.layers.7.mixer.in_proj.weight', 'model.layers.7.mixer.conv1d.weight', 'model.layers.7.mixer.conv1d.bias', 'model.layers.7.mixer.out_proj.weight', 'model.layers.9.mixer.z_bias', 'model.layers.9.mixer.D', 'model.layers.9.mixer.in_proj.weight', 'model.layers.9.mixer.conv1d.weight', 'model.layers.9.mixer.conv1d.bias', 'model.layers.9.mixer.out_proj.weight', 'model.layers.10.mixer.z_bias', 'model.layers.10.mixer.D', 'model.layers.10.mixer.in_proj.weight', 'model.layers.10.mixer.conv1d.weight', 'model.layers.10.mixer.conv1d.bias', 'model.layers.10.mixer.out_proj.weight', 'model.layers.11.mixer.z_bias', 'model.layers.11.mixer.D', 'model.layers.11.mixer.in_proj.weight', 'model.layers.11.mixer.conv1d.weight', 'model.layers.11.mixer.conv1d.bias', 'model.layers.11.mixer.out_proj.weight', 'model.layers.12.mixer.z_bias', 'model.layers.12.mixer.D', 'model.layers.12.mixer.in_proj.weight', 'model.layers.12.mixer.conv1d.weight', 'model.layers.12.mixer.conv1d.bias', 'model.layers.12.mixer.out_proj.weight', 'model.layers.13.mixer.z_bias', 'model.layers.13.mixer.D', 'model.layers.13.mixer.in_proj.weight', 'model.layers.13.mixer.conv1d.weight', 'model.layers.13.mixer.conv1d.bias', 'model.layers.13.mixer.out_proj.weight', 'model.layers.14.mixer.z_bias', 'model.layers.14.mixer.D', 'model.layers.14.mixer.in_proj.weight', 'model.layers.14.mixer.conv1d.weight', 'model.layers.14.mixer.conv1d.bias', 'model.layers.14.mixer.out_proj.weight', 'model.layers.15.mixer.z_bias', 'model.layers.15.mixer.D', 'model.layers.15.mixer.in_proj.weight', 'model.layers.15.mixer.conv1d.weight', 'model.layers.15.mixer.conv1d.bias', 'model.layers.15.mixer.out_proj.weight', 'model.layers.28.mixer.z_bias', 'model.layers.28.mixer.D', 'model.layers.28.mixer.in_proj.weight', 'model.layers.28.mixer.conv1d.weight', 'model.layers.28.mixer.conv1d.bias', 'model.layers.28.mixer.out_proj.weight', 'model.layers.32.mixer.z_bias', 'model.layers.32.mixer.D', 'model.layers.32.mixer.in_proj.weight', 'model.layers.32.mixer.conv1d.weight', 'model.layers.32.mixer.conv1d.bias', 'model.layers.32.mixer.out_proj.weight', 'model.layers.36.mixer.z_bias', 'model.layers.36.mixer.D', 'model.layers.36.mixer.in_proj.weight', 'model.layers.36.mixer.conv1d.weight', 'model.layers.36.mixer.conv1d.bias', 'model.layers.36.mixer.out_proj.weight', 'model.layers.37.mixer.z_bias', 'model.layers.37.mixer.D', 'model.layers.37.mixer.in_proj.weight', 'model.layers.37.mixer.conv1d.weight', 'model.layers.37.mixer.conv1d.bias', 'model.layers.37.mixer.out_proj.weight', 'model.layers.38.mixer.z_bias', 'model.layers.38.mixer.D', 'model.layers.38.mixer.in_proj.weight', 'model.layers.38.mixer.conv1d.weight', 'model.layers.38.mixer.conv1d.bias', 'model.layers.38.mixer.out_proj.weight', 'model.layers.39.mixer.z_bias', 'model.layers.39.mixer.D', 'model.layers.39.mixer.in_proj.weight', 'model.layers.39.mixer.conv1d.weight', 'model.layers.39.mixer.conv1d.bias', 'model.layers.39.mixer.out_proj.weight', 'model.layers.40.mixer.z_bias', 'model.layers.40.mixer.D', 'model.layers.40.mixer.in_proj.weight', 'model.layers.40.mixer.conv1d.weight', 'model.layers.40.mixer.conv1d.bias', 'model.layers.40.mixer.out_proj.weight', 'model.layers.45.mixer.z_bias', 'model.layers.45.mixer.D', 'model.layers.45.mixer.in_proj.weight', 'model.layers.45.mixer.conv1d.weight', 'model.layers.45.mixer.conv1d.bias', 'model.layers.45.mixer.out_proj.weight', 'model.layers.48.mixer.z_bias', 'model.layers.48.mixer.D', 'model.layers.48.mixer.in_proj.weight', 'model.layers.48.mixer.conv1d.weight', 'model.layers.48.mixer.conv1d.bias', 'model.layers.48.mixer.out_proj.weight', 'model.layers.49.mixer.z_bias', 'model.layers.49.mixer.D', 'model.layers.49.mixer.in_proj.weight', 'model.layers.49.mixer.conv1d.weight', 'model.layers.49.mixer.conv1d.bias', 'model.layers.49.mixer.out_proj.weight']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# layer_ids = \"47\"\n",
    "sdm = model_mohawk.state_dict()\n",
    "# layer_sd = {k: v for k, v in sdm.items() if f\"layers.{layer_ids}\" in k}.copy()\n",
    "# r = model_l3.load_state_dict(layer_sd, strict=False)\n",
    "r = model_l3.load_state_dict(sdm, strict=False)\n",
    "print(r.unexpected_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_l3.save_pretrained(\"/mnt/checkpoints/ssm/iterative_hybrids_only_new_layer_train/apriel_ssm_thinker15b_hybrid_3ssm_leastimportant_32h_init_mohawk_layer24\")\n",
    "model_l3.save_pretrained(\"/mnt/checkpoints/ssm/apriel_ssm_thinker15b_hybrid_25ssm_leastimportant_32h_init_mohawk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/toolkit/dev/fml-ops/__oo_playground\")\n",
    "from results_analysis.results_loader import ResultsLoader\n",
    "layer_importance_path = \"/mnt/evaluations/training_evaluation/model_runs/lm_eval_runner/apriel_ssm_importance/\"\n",
    "results_loader = ResultsLoader(layer_importance_path)\n",
    "\n",
    "results_loader.deserialize_results()\n",
    "results_df = results_loader.to_df()\n",
    "results_df[\"layer_index\"] = results_df.apply(lambda row: int(row[\"model_name_sanitized\"].split(\"_\")[-1] if \"layers_\" in row[\"model_name_sanitized\"] else -1), axis=1)\n",
    "results_df = results_df[results_df[\"metric\"] == \"acc\"]\n",
    "columns_to_keep = [\"layer_index\", \"metric_value\"]\n",
    "results_df = results_df[columns_to_keep]\n",
    "layer_importance = results_df.groupby(\"layer_index\").mean()\n",
    "layer_importance = layer_importance.sort_values(by=\"metric_value\", ascending=False).reset_index()\n",
    "layer_importance = layer_importance[layer_importance[\"layer_index\"]!= -1]\n",
    "layer_importance = list(layer_importance[\"layer_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 31\u001b[0m\n\u001b[1;32m     14\u001b[0m hybrid_block_layout \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm2d\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     16\u001b[0m config_hybrid \u001b[38;5;241m=\u001b[39m AprielSSMHybridConfig(\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_thinker\u001b[38;5;241m.\u001b[39mto_dict(),\n\u001b[1;32m     18\u001b[0m     hybrid_block_layout\u001b[38;5;241m=\u001b[39mhybrid_block_layout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m         }\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 31\u001b[0m model_hybrid \u001b[38;5;241m=\u001b[39m \u001b[43mAprielSSMHybridForCausalLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_hybrid\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/Fast-LLM/fast_llm/models/ssm/external/apriel_15b_hybrid/modeling_ssm_hybrid_apriel15b.py:958\u001b[0m, in \u001b[0;36mAprielSSMHybridForCausalLM.__init__\u001b[0;34m(self, config, **kwargs)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: AprielSSMHybridConfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 958\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAprielSSMHybridModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mhidden_size, config\u001b[38;5;241m.\u001b[39mvocab_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/dev/Fast-LLM/fast_llm/models/ssm/external/apriel_15b_hybrid/modeling_ssm_hybrid_apriel15b.py:802\u001b[0m, in \u001b[0;36mAprielSSMHybridModel.__init__\u001b[0;34m(self, config, **kwargs)\u001b[0m\n\u001b[1;32m    800\u001b[0m     blocks\u001b[38;5;241m.\u001b[39mappend(AprielSSMDecoderLayer(config, layer_idx))\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 802\u001b[0m     blocks\u001b[38;5;241m.\u001b[39mappend(\u001b[43mMistralDecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    804\u001b[0m     blocks\u001b[38;5;241m.\u001b[39mappend(AprielHybridIdentity(config))\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:224\u001b[0m, in \u001b[0;36mMistralDecoderLayer.__init__\u001b[0;34m(self, config, layer_idx)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mhidden_size\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m MistralAttention(config\u001b[38;5;241m=\u001b[39mconfig, layer_idx\u001b[38;5;241m=\u001b[39mlayer_idx)\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m \u001b[43mMistralMLP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm \u001b[38;5;241m=\u001b[39m MistralRMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm \u001b[38;5;241m=\u001b[39m MistralRMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:49\u001b[0m, in \u001b[0;36mMistralMLP.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mintermediate_size\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn \u001b[38;5;241m=\u001b[39m ACT2FN[config\u001b[38;5;241m.\u001b[39mhidden_act]\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/torch/nn/modules/linear.py:112\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/torch/nn/modules/linear.py:118\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         fan_in, _ \u001b[38;5;241m=\u001b[39m init\u001b[38;5;241m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n",
      "File \u001b[0;32m~/.conda/envs/fast_llm/lib/python3.12/site-packages/torch/nn/init.py:518\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity, generator)\u001b[0m\n\u001b[1;32m    516\u001b[0m bound \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m) \u001b[38;5;241m*\u001b[39m std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_thinker = \"/mnt/checkpoints/upstream/Apriel-Nemotron-15b-Thinker\"\n",
    "n_ssm = 50\n",
    "\n",
    "config_thinker = AutoConfig.from_pretrained(path_thinker)\n",
    "hybrid_block_layout = [\"t\"] * config_thinker.num_hidden_layers\n",
    "# hybrid_block_layout[0] = \"m2d\"\n",
    "\n",
    "for i in range(n_ssm):\n",
    "    # hybrid_block_layout[layer_importance[i]] = \"m2d\"\n",
    "    if i % 2 == 0:\n",
    "        # hybrid_block_layout[layer_importance[i]] = \"m2d\"\n",
    "        hybrid_block_layout[i] = \"m2d\"\n",
    "\n",
    "hybrid_block_layout = [\"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"t\", \"m2d\", \"t\", \"t\", \"t\", \"m2d\", \"t\", \"t\", \"t\", \"t\", \"t\", \"m2d\", \"m2d\", \"t\", \"t\", \"t\", \"t\", \"m2d\", \"m2d\", \"m2d\", \"m2d\", \"t\", \"t\", \"t\", \"m2d\", \"t\", \"t\", \"t\", \"m2d\", \"t\", \"m2d\"]\n",
    "\n",
    "config_hybrid = AprielSSMHybridConfig(\n",
    "    **config_thinker.to_dict(),\n",
    "    hybrid_block_layout=hybrid_block_layout,\n",
    "    ssm_cfg = {\n",
    "            \"d_state\": 64,\n",
    "            \"n_v_heads\": 32,\n",
    "            \"n_qk_heads\": 32,\n",
    "            \"expand\": 1,\n",
    "            \"chunk_size\": 128,\n",
    "            \"activation\": \"identity\",\n",
    "            \"bias\": False,\n",
    "            \"d_conv\": 4,\n",
    "            \"d_inner\": 32 * 128\n",
    "        }\n",
    ")\n",
    "model_hybrid = AprielSSMHybridForCausalLM(config_hybrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'm2d',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'm2d',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 'm2d',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'm2d',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'm2d',\n",
       " 't',\n",
       " 'm2d']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_block_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:28<00:00,  4.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['model.layers.20.mixer.z_bias', 'model.layers.20.mixer.D', 'model.layers.20.mixer.in_proj.weight', 'model.layers.20.mixer.conv1d.weight', 'model.layers.20.mixer.conv1d.bias', 'model.layers.20.mixer.out_proj.weight', 'model.layers.24.mixer.z_bias', 'model.layers.24.mixer.D', 'model.layers.24.mixer.in_proj.weight', 'model.layers.24.mixer.conv1d.weight', 'model.layers.24.mixer.conv1d.bias', 'model.layers.24.mixer.out_proj.weight', 'model.layers.30.mixer.z_bias', 'model.layers.30.mixer.D', 'model.layers.30.mixer.in_proj.weight', 'model.layers.30.mixer.conv1d.weight', 'model.layers.30.mixer.conv1d.bias', 'model.layers.30.mixer.out_proj.weight', 'model.layers.31.mixer.z_bias', 'model.layers.31.mixer.D', 'model.layers.31.mixer.in_proj.weight', 'model.layers.31.mixer.conv1d.weight', 'model.layers.31.mixer.conv1d.bias', 'model.layers.31.mixer.out_proj.weight', 'model.layers.36.mixer.z_bias', 'model.layers.36.mixer.D', 'model.layers.36.mixer.in_proj.weight', 'model.layers.36.mixer.conv1d.weight', 'model.layers.36.mixer.conv1d.bias', 'model.layers.36.mixer.out_proj.weight', 'model.layers.37.mixer.z_bias', 'model.layers.37.mixer.D', 'model.layers.37.mixer.in_proj.weight', 'model.layers.37.mixer.conv1d.weight', 'model.layers.37.mixer.conv1d.bias', 'model.layers.37.mixer.out_proj.weight', 'model.layers.38.mixer.z_bias', 'model.layers.38.mixer.D', 'model.layers.38.mixer.in_proj.weight', 'model.layers.38.mixer.conv1d.weight', 'model.layers.38.mixer.conv1d.bias', 'model.layers.38.mixer.out_proj.weight', 'model.layers.39.mixer.z_bias', 'model.layers.39.mixer.D', 'model.layers.39.mixer.in_proj.weight', 'model.layers.39.mixer.conv1d.weight', 'model.layers.39.mixer.conv1d.bias', 'model.layers.39.mixer.out_proj.weight', 'model.layers.43.mixer.z_bias', 'model.layers.43.mixer.D', 'model.layers.43.mixer.in_proj.weight', 'model.layers.43.mixer.conv1d.weight', 'model.layers.43.mixer.conv1d.bias', 'model.layers.43.mixer.out_proj.weight', 'model.layers.47.mixer.z_bias', 'model.layers.47.mixer.D', 'model.layers.47.mixer.in_proj.weight', 'model.layers.47.mixer.conv1d.weight', 'model.layers.47.mixer.conv1d.bias', 'model.layers.47.mixer.out_proj.weight', 'model.layers.49.mixer.z_bias', 'model.layers.49.mixer.D', 'model.layers.49.mixer.in_proj.weight', 'model.layers.49.mixer.conv1d.weight', 'model.layers.49.mixer.conv1d.bias', 'model.layers.49.mixer.out_proj.weight'], unexpected_keys=['model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.36.self_attn.q_proj.weight', 'model.layers.36.self_attn.k_proj.weight', 'model.layers.36.self_attn.v_proj.weight', 'model.layers.36.self_attn.o_proj.weight', 'model.layers.37.self_attn.q_proj.weight', 'model.layers.37.self_attn.k_proj.weight', 'model.layers.37.self_attn.v_proj.weight', 'model.layers.37.self_attn.o_proj.weight', 'model.layers.38.self_attn.q_proj.weight', 'model.layers.38.self_attn.k_proj.weight', 'model.layers.38.self_attn.v_proj.weight', 'model.layers.38.self_attn.o_proj.weight', 'model.layers.39.self_attn.q_proj.weight', 'model.layers.39.self_attn.k_proj.weight', 'model.layers.39.self_attn.v_proj.weight', 'model.layers.39.self_attn.o_proj.weight', 'model.layers.43.self_attn.q_proj.weight', 'model.layers.43.self_attn.k_proj.weight', 'model.layers.43.self_attn.v_proj.weight', 'model.layers.43.self_attn.o_proj.weight', 'model.layers.47.self_attn.q_proj.weight', 'model.layers.47.self_attn.k_proj.weight', 'model.layers.47.self_attn.v_proj.weight', 'model.layers.47.self_attn.o_proj.weight', 'model.layers.49.self_attn.q_proj.weight', 'model.layers.49.self_attn.k_proj.weight', 'model.layers.49.self_attn.v_proj.weight', 'model.layers.49.self_attn.o_proj.weight'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_base = path_thinker\n",
    "model_base = MistralForCausalLM.from_pretrained(path_base)\n",
    "\n",
    "model_hybrid.load_state_dict(model_base.state_dict(), strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_hybrid.save_pretrained(\"/mnt/checkpoints/ssm/apriel_ssm_thinker15b_hybrid_1ssm_leastimportant_32h_init_rand\") # 1 ssm\n",
    "# model_hybrid.save_pretrained(\"/mnt/checkpoints/ssm/apriel_ssm_thinker15b_hybrid_1ssm_0th_32h_init_rand\") # 1 ssm\n",
    "# model_hybrid.save_pretrained(\"/mnt/checkpoints/ssm/apriel_ssm_thinker15b_hybrid_interleaved_ssm_starting0th_32h_init_rand\") # 1 ssm\n",
    "model_hybrid.save_pretrained(\"/mnt/checkpoints/ssm/apriel_ssm_thinker15b_hybrid_10ssm_leastimportant_32h_init_rand\") # 1 ssm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:40<00:00,  5.77s/it]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "path = \"/mnt/checkpoints/ssm/apriel_ssm_thinker15b_hybrid_25ssm_leastimportant_32h_init_rand\"\n",
    "model = AprielSSMHybridForCausalLM.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:  29%|██▊       | 2/7 [00:11<00:27,  5.53s/it]"
     ]
    }
   ],
   "source": [
    "path_base = \"/mnt/checkpoints/upstream/Apriel-Nemotron-15b-Thinker\"\n",
    "model_base = MistralForCausalLM.from_pretrained(path_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
